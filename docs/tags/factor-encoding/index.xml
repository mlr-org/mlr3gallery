<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>factor encoding on mlr3 gallery</title>
    <link>/tags/factor-encoding/</link>
    <description>Recent content in factor encoding on mlr3 gallery</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 31 Jan 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/factor-encoding/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Encode factor levels for xgboost</title>
      <link>/encode-factors-for-xgboost/</link>
      <pubDate>Fri, 31 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/encode-factors-for-xgboost/</guid>
      <description>The package xgboost unfortunately does not support handling of categorical features. Therefore it is required to manually convert factor columns to numerical dummy features. We show how to use mlr3pipelines to augment the xgboost learner with an automatic factor encoding.
Construct the Base Objects First, we take an example task with factors (german_credit) and create the xgboost learner:
library(mlr3) library(mlr3learners) task = tsk(&amp;quot;german_credit&amp;quot;) print(task) ## &amp;lt;TaskClassif:german_credit&amp;gt; (1000 x 21) ## * Target: credit_risk ## * Properties: twoclass ## * Features (20): ## - fct (12): credit_history, foreign_worker, housing, job, ## other_debtors, other_installment_plans, personal_status_sex, ## property, purpose, savings, status, telephone ## - dbl (7): age, amount, duration, installment_rate, number_credits, ## people_liable, present_residence ## - ord (1): employment_duration learner = lrn(&amp;quot;classif.</description>
    </item>
    
  </channel>
</rss>