<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.67.0" />


<title>A pipeline for the titanic data set - mlr3 gallery</title>
<meta property="og:title" content="A pipeline for the titanic data set - mlr3 gallery">


  <link href='/favicon.ico' rel='icon' type='image/x-icon'/>



  








<link href='//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/gruvbox-dark.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">

<link rel="stylesheet" href="/css/custom.css">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/logo.png"
         width="50"
         height="50"
         alt="mlr logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="https://github.com/mlr-org/mlr3gallery">GitHub</a></li>
    
    <li><a href="https://mlr3.mlr-org.com">mlr3</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">10 min read</span>
    

    <h1 class="article-title">A pipeline for the titanic data set</h1>

    
    <span class="article-date">2020-03-12 by Florian Pfisterer</span>
    

    <div class="article-content">
      


<div id="intro" class="section level2">
<h2>Intro</h2>
<p>First of all we are going to load required packages and the data. The data is part of the <code>mlr3data</code> package.</p>
<pre class="r"><code>library(&quot;mlr3&quot;)
library(&quot;mlr3learners&quot;)
library(&quot;mlr3pipelines&quot;)
library(&quot;mlr3data&quot;)
library(&quot;mlr3misc&quot;)
data(&quot;titanic&quot;)</code></pre>
<p>The titanic data is very interesting to analyze, even though it is part of many tutorials and showcases. This is because it requires many steps often required in real-world applications of machine learning techniques, such as <strong>feature engineering</strong>, <strong>missing value imputation</strong>, <strong>handling factors</strong> and others.</p>
<p>In order to obtain solutions comparable to official leaderboards, such as the ones available from CRAN, we split the data into train and test set before doing any further analysis.</p>
<pre class="r"><code>titanic_train = titanic[1:891, ]
titanic_test = titanic[892:1309, ]</code></pre>
</div>
<div id="exploratory-data-analysis" class="section level2">
<h2>Exploratory Data Analysis</h2>
<p>With the dataset, we get an explanation of the meanings of the different variables:</p>
<pre><code>survived        Survival
                (0 = No; 1 = Yes)
pclass          Passenger Class
                (1 = 1st; 2 = 2nd; 3 = 3rd)
name            Name
sex             Sex
age             Age
sibsp           Number of Siblings/Spouses Aboard
parch           Number of Parents/Children Aboard
ticket          Ticket Number
fare            Passenger Fare
cabin           Cabin
embarked        Port of Embarkation
                (C = Cherbourg; Q = Queenstown; S = Southampton)</code></pre>
<p>We can use the <code>skimr</code> package in order to get a first overview of the data:</p>
<pre class="r"><code>skimr::skim(titanic_train)</code></pre>
<table>
<caption><span id="tab:unnamed-chunk-4">Table 1: </span>Data summary</caption>
<tbody>
<tr class="odd">
<td align="left">Name</td>
<td align="left">titanic_train</td>
</tr>
<tr class="even">
<td align="left">Number of rows</td>
<td align="left">891</td>
</tr>
<tr class="odd">
<td align="left">Number of columns</td>
<td align="left">11</td>
</tr>
<tr class="even">
<td align="left">_______________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Column type frequency:</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">character</td>
<td align="left">3</td>
</tr>
<tr class="odd">
<td align="left">factor</td>
<td align="left">4</td>
</tr>
<tr class="even">
<td align="left">numeric</td>
<td align="left">4</td>
</tr>
<tr class="odd">
<td align="left">________________________</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">Group variables</td>
<td align="left">None</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: character</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">min</th>
<th align="right">max</th>
<th align="right">empty</th>
<th align="right">n_unique</th>
<th align="right">whitespace</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">name</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">12</td>
<td align="right">82</td>
<td align="right">0</td>
<td align="right">891</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">ticket</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">3</td>
<td align="right">18</td>
<td align="right">0</td>
<td align="right">681</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">cabin</td>
<td align="right">687</td>
<td align="right">0.23</td>
<td align="right">1</td>
<td align="right">15</td>
<td align="right">0</td>
<td align="right">147</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: factor</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="left">ordered</th>
<th align="right">n_unique</th>
<th align="left">top_counts</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">survived</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">2</td>
<td align="left">0: 549, 1: 342</td>
</tr>
<tr class="even">
<td align="left">pclass</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">TRUE</td>
<td align="right">3</td>
<td align="left">3: 491, 1: 216, 2: 184</td>
</tr>
<tr class="odd">
<td align="left">sex</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">2</td>
<td align="left">mal: 577, fem: 314</td>
</tr>
<tr class="even">
<td align="left">embarked</td>
<td align="right">2</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">3</td>
<td align="left">S: 644, C: 168, Q: 77</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">p0</th>
<th align="right">p25</th>
<th align="right">p50</th>
<th align="right">p75</th>
<th align="right">p100</th>
<th align="left">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">age</td>
<td align="right">177</td>
<td align="right">0.8</td>
<td align="right">29.70</td>
<td align="right">14.53</td>
<td align="right">0.42</td>
<td align="right">20.12</td>
<td align="right">28.00</td>
<td align="right">38</td>
<td align="right">80.00</td>
<td align="left">▂▇▅▂▁</td>
</tr>
<tr class="even">
<td align="left">sib_sp</td>
<td align="right">0</td>
<td align="right">1.0</td>
<td align="right">0.52</td>
<td align="right">1.10</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">1</td>
<td align="right">8.00</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="odd">
<td align="left">parch</td>
<td align="right">0</td>
<td align="right">1.0</td>
<td align="right">0.38</td>
<td align="right">0.81</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0</td>
<td align="right">6.00</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">fare</td>
<td align="right">0</td>
<td align="right">1.0</td>
<td align="right">32.20</td>
<td align="right">49.69</td>
<td align="right">0.00</td>
<td align="right">7.91</td>
<td align="right">14.45</td>
<td align="right">31</td>
<td align="right">512.33</td>
<td align="left">▇▁▁▁▁</td>
</tr>
</tbody>
</table>
<pre class="r"><code>skimr::skim(titanic_test)</code></pre>
<table>
<caption><span id="tab:unnamed-chunk-4">Table 1: </span>Data summary</caption>
<tbody>
<tr class="odd">
<td align="left">Name</td>
<td align="left">titanic_test</td>
</tr>
<tr class="even">
<td align="left">Number of rows</td>
<td align="left">418</td>
</tr>
<tr class="odd">
<td align="left">Number of columns</td>
<td align="left">11</td>
</tr>
<tr class="even">
<td align="left">_______________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Column type frequency:</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">character</td>
<td align="left">3</td>
</tr>
<tr class="odd">
<td align="left">factor</td>
<td align="left">4</td>
</tr>
<tr class="even">
<td align="left">numeric</td>
<td align="left">4</td>
</tr>
<tr class="odd">
<td align="left">________________________</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">Group variables</td>
<td align="left">None</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: character</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">min</th>
<th align="right">max</th>
<th align="right">empty</th>
<th align="right">n_unique</th>
<th align="right">whitespace</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">name</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">13</td>
<td align="right">63</td>
<td align="right">0</td>
<td align="right">418</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">ticket</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">3</td>
<td align="right">18</td>
<td align="right">0</td>
<td align="right">363</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">cabin</td>
<td align="right">327</td>
<td align="right">0.22</td>
<td align="right">1</td>
<td align="right">15</td>
<td align="right">0</td>
<td align="right">76</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: factor</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="left">ordered</th>
<th align="right">n_unique</th>
<th align="left">top_counts</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">survived</td>
<td align="right">418</td>
<td align="right">0</td>
<td align="left">FALSE</td>
<td align="right">0</td>
<td align="left">0: 0, 1: 0</td>
</tr>
<tr class="even">
<td align="left">pclass</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">TRUE</td>
<td align="right">3</td>
<td align="left">3: 218, 1: 107, 2: 93</td>
</tr>
<tr class="odd">
<td align="left">sex</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">2</td>
<td align="left">mal: 266, fem: 152</td>
</tr>
<tr class="even">
<td align="left">embarked</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">3</td>
<td align="left">S: 270, C: 102, Q: 46</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">p0</th>
<th align="right">p25</th>
<th align="right">p50</th>
<th align="right">p75</th>
<th align="right">p100</th>
<th align="left">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">age</td>
<td align="right">86</td>
<td align="right">0.79</td>
<td align="right">30.27</td>
<td align="right">14.18</td>
<td align="right">0.17</td>
<td align="right">21.0</td>
<td align="right">27.00</td>
<td align="right">39.0</td>
<td align="right">76.00</td>
<td align="left">▂▇▃▂▁</td>
</tr>
<tr class="even">
<td align="left">sib_sp</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">0.45</td>
<td align="right">0.90</td>
<td align="right">0.00</td>
<td align="right">0.0</td>
<td align="right">0.00</td>
<td align="right">1.0</td>
<td align="right">8.00</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="odd">
<td align="left">parch</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">0.39</td>
<td align="right">0.98</td>
<td align="right">0.00</td>
<td align="right">0.0</td>
<td align="right">0.00</td>
<td align="right">0.0</td>
<td align="right">9.00</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">fare</td>
<td align="right">1</td>
<td align="right">1.00</td>
<td align="right">35.63</td>
<td align="right">55.91</td>
<td align="right">0.00</td>
<td align="right">7.9</td>
<td align="right">14.45</td>
<td align="right">31.5</td>
<td align="right">512.33</td>
<td align="left">▇▁▁▁▁</td>
</tr>
</tbody>
</table>
<p>Here we can also inspect the data for differences in the train and test set. This might be important, as shifts in the data distribution often make our models unreliable.</p>
<pre class="r"><code>DataExplorer::plot_bar(titanic_train, nrow = 5, ncol = 3)
#&gt; 3 columns ignored with more than 50 categories.
#&gt; name: 891 categories
#&gt; ticket: 681 categories
#&gt; cabin: 148 categories</code></pre>
<p><img src="/post/intro_pipelines_titanic_files/figure-html/unnamed-chunk-5-1.png" width="100%" /></p>
<pre class="r"><code>DataExplorer::plot_histogram(titanic_train, nrow = 2, ncol = 3)</code></pre>
<p><img src="/post/intro_pipelines_titanic_files/figure-html/unnamed-chunk-6-1.png" width="100%" /></p>
<pre class="r"><code>DataExplorer::plot_boxplot(titanic_train, by = &quot;survived&quot;, nrow = 2, ncol = 3)</code></pre>
<p><img src="/post/intro_pipelines_titanic_files/figure-html/unnamed-chunk-6-2.png" width="100%" /></p>
<p>We can now create a <code>Task</code> from our data. As we want to classify whether the person survived or not, we will create a <code>TaskClassif</code>. We’ll ignore the ‘titanic_test’ data for now and come back to it later.</p>
</div>
<div id="a-first-model" class="section level2">
<h2>A first model</h2>
<pre class="r"><code>task = TaskClassif$new(&quot;titanic&quot;, titanic_train, target = &quot;survived&quot;, positive = &quot;1&quot;)
task
#&gt; &lt;TaskClassif:titanic&gt; (891 x 11)
#&gt; * Target: survived
#&gt; * Properties: twoclass
#&gt; * Features (10):
#&gt;   - chr (3): cabin, name, ticket
#&gt;   - dbl (2): age, fare
#&gt;   - fct (2): embarked, sex
#&gt;   - int (2): parch, sib_sp
#&gt;   - ord (1): pclass</code></pre>
<p>Our <code>Task</code> currently has <span class="math inline">\(3\)</span> features of type <code>character</code>, which we don’t really know how to handle: “Cabin”, “Name”, “Ticket” and “PassengerId”. Additionally, from our <code>skim</code> of the data, we have seen, that they have many unique values (up to 891).</p>
<p>We’ll drop them for now and see how we can deal with them later on.</p>
<pre class="r"><code>task$select(cols = setdiff(task$feature_names, c(&quot;cabin&quot;, &quot;name&quot;, &quot;ticket&quot;)))</code></pre>
<p>Additionally, we create a resampling instance that allows to compare data.</p>
<pre class="r"><code>rdesc = rsmp(&quot;cv&quot;, folds = 3L)$instantiate(task)</code></pre>
<p>To get a first impression of what performance we can fit a simple decision tree:</p>
<pre class="r"><code>learner = mlr_learners$get(&quot;classif.rpart&quot;)
res = resample(task, learner, rdesc, store_models = TRUE)
agg = res$aggregate(msr(&quot;classif.acc&quot;))
agg
#&gt; classif.acc 
#&gt;   0.8080808</code></pre>
<p>So our model should have a minimal accuracy of 0.808 in order to improve over the simple decision tree.</p>
<p>If we now try to fit a ‘ranger’ random forest model, we will get an error, as ‘ranger’ models can not naturally handle missing values.</p>
<pre class="r"><code>learner = lrn(&quot;classif.ranger&quot;)
learner$param_set$values = list(num.trees = 250, min.node.size = 4)
res = resample(task, learner, rdesc, store_models = TRUE)
#&gt; Error: Missing data in columns: age, embarked.</code></pre>
<p>This means we have to find a way to impute the missing values.</p>
</div>
<div id="imputation" class="section level2">
<h2>Imputation</h2>
<p>A very simple way to do this to just impute a constant value for each feature, we could i.e. impute every <code>character</code> or <code>factor</code> column with <code>missing</code> and every numeric column with <code>-999</code>. And depending on the model, this might actually be fine. This approach has a few drawbacks though:</p>
<ul>
<li><code>-999</code> could be a real value in the data.</li>
<li>imputing <code>-999</code> skews the distribution of the data, which might result in bad models.</li>
</ul>
<p>As a result, instead of imputing a constant value, we will do two things: * Draw samples from each numeric features’ histogram using <code>PipeOpImputeHist</code> * Add an additional column for each <code>variable</code> that indicates whether a value was missing or not. If the information that a value was missing is important, this column contains this information.</p>
<p>This imputation scheme is called ‘imputation with constants’ and is already implemented in <code>mlr3pipelines</code>. It can be done using <code>PipeOpImputeConstant</code>.</p>
<p>Before imputation, our data looks as follows:</p>
<pre class="r"><code>task$missings()
#&gt; survived      age embarked     fare    parch   pclass      sex   sib_sp 
#&gt;        0      177        2        0        0        0        0        0</code></pre>
<p>Let’s first deal with the categorical variables:</p>
<pre class="r"><code>po_newlvl = po(&quot;imputenewlvl&quot;)
task_newlvl = po_newlvl$train(list(task))[[1]]</code></pre>
<p>Note that we use the <code>PipeOp</code> in an unusual way, which is why the syntax does not look very clean. We’ll learn how to use a full graph below.</p>
<p>First, let’s look at the result:</p>
<pre class="r"><code>task_newlvl$missings()
#&gt; survived      age     fare    parch   pclass      sex   sib_sp embarked 
#&gt;        0      177        0        0        0        0        0        0</code></pre>
<p>Cool! <code>embarked</code> does not have missing values anymore. Note that <code>PipeOpImputeNewLvl</code> by default affects <code>character</code>, <code>factor</code> and <code>ordered</code> columns.</p>
<p>For the <code>numeric</code> features we want to do two things, impute values and add an indicator column. In order to do this, we need a more complicated structure, a <code>Graph</code>.</p>
<p>Our <code>po_indicator</code> creates the indicator column. We tell it to only do this for <code>numeric</code> and <code>integer</code> columns via its <code>param_vals</code>, and additionally tell it to create a numeric column (0 = “not missing”, 1 = “missing”).</p>
<pre class="r"><code>po_indicator = po(&quot;missind&quot;,
  param_vals = list(affect_columns = selector_type(c(&quot;numeric&quot;, &quot;integer&quot;)), type = &quot;numeric&quot;))</code></pre>
<p>Now we can simultaneously impute features from the histogram and create indicator columns. This can be achieved using the <code>gunion</code> function, which puts two operations in parallel:</p>
<pre class="r"><code>gr = gunion(list(po_indicator, po(&quot;imputehist&quot;)))
gr = gr %&gt;&gt;% po(&quot;featureunion&quot;)</code></pre>
<p>Afterwards, we <code>cbind</code> the resulting data using <code>po(&quot;featureunion&quot;)</code>, connecting the different operations using our <strong>graph connector</strong>: <code>%&gt;&gt;%</code>.</p>
<p>We can now also connect the newlvl imputation:</p>
<pre class="r"><code>gr = gr %&gt;&gt;% po(&quot;imputenewlvl&quot;)</code></pre>
<p>and see what happens when we now train the whole <strong>Graph</strong>:</p>
<pre class="r"><code>task_imputed = gr$clone()$train(task)[[1]]
task_imputed$missings()
#&gt;    survived missing_age      pclass         sex        fare       parch      sib_sp 
#&gt;           0           0           0           0           0           0           0 
#&gt;         age    embarked 
#&gt;           0           0</code></pre>
<p>Awesome, no more missing values!</p>
<p>We could now use <code>task_imputed</code> for resampling and see whether a <strong>ranger</strong> model does better. But this is dangerous! If we preprocess all training data at once, data could leak through the different cross-validation folds. In order to do this properly, we have to process the training data in every fold separately. Luckily, this is automatically handled in our <code>Graph</code>, if we use it through a <code>GraphLearner</code>.</p>
<p>We can simple append a <code>ranger</code> learner to the Graph and create a <code>GraphLearner</code> from this.</p>
<pre class="r"><code>glrn = GraphLearner$new(gr$clone() %&gt;&gt;% po(learner))</code></pre>
<pre class="r"><code>res = resample(task, glrn, rdesc, store_models = TRUE)
agg = res$aggregate(msr(&quot;classif.acc&quot;))
agg
#&gt; classif.acc 
#&gt;   0.8260382</code></pre>
<p>So our model has not improved heavily, currently it has an accuracy of 0.826. In order to improve more, we might need to do some feature engineering.</p>
</div>
<div id="feature-engineering" class="section level2">
<h2>Feature Engineering</h2>
<p>We will do this using <code>PipeOpMutate</code> in order to showcase the power of <code>mlr3pipelines</code>. Additionally, we will make use of the <code>character</code> columns, and thus re-select them:</p>
<pre class="r"><code>task$col_roles$feature = c(task$feature_names, c(&quot;cabin&quot;, &quot;name&quot;, &quot;ticket&quot;))</code></pre>
<pre class="r"><code>library(&quot;stringi&quot;)
po_ftextract = po(&quot;mutate&quot;, param_vals = list(
    mutation = list(
      fare_per_person = ~ fare / (parch + sib_sp + 1),
      deck = ~ factor(stri_sub(cabin, 1,1)),
      portside = ~ as.numeric(stri_extract_last_regex(cabin, &quot;[0-9]&quot;)) %% 2,
      title = ~ factor(stri_match(name, regex = &quot;, (.*)\\.&quot;)[,2]),
      surname = ~ factor(stri_match(name, regex = &quot;(.*),&quot;)[,2]),
      ticket_prefix = ~ factor(stri_replace_all_fixed(stri_trim(stri_match(ticket, regex =&quot;(.*) &quot;)[, 2]), &quot;.&quot;, &quot;&quot;))
    )
))</code></pre>
<p>Quickly checking what happens:</p>
<pre class="r"><code>task_eng = po_ftextract$clone()$train(list(task))[[1]]
task_eng$data()
#&gt;      survived age embarked    fare parch pclass    sex sib_sp cabin
#&gt;   1:        0  22        S  7.2500     0      3   male      1  &lt;NA&gt;
#&gt;   2:        1  38        C 71.2833     0      1 female      1   C85
#&gt;   3:        1  26        S  7.9250     0      3 female      0  &lt;NA&gt;
#&gt;   4:        1  35        S 53.1000     0      1 female      1  C123
#&gt;   5:        0  35        S  8.0500     0      3   male      0  &lt;NA&gt;
#&gt;  ---                                                               
#&gt; 887:        0  27        S 13.0000     0      2   male      0  &lt;NA&gt;
#&gt; 888:        1  19        S 30.0000     0      1 female      0   B42
#&gt; 889:        0  NA        S 23.4500     2      3 female      1  &lt;NA&gt;
#&gt; 890:        1  26        C 30.0000     0      1   male      0  C148
#&gt; 891:        0  32        Q  7.7500     0      3   male      0  &lt;NA&gt;
#&gt;                                                     name           ticket fare_per_person
#&gt;   1:                             Braund, Mr. Owen Harris        A/5 21171         3.62500
#&gt;   2: Cumings, Mrs. John Bradley (Florence Briggs Thayer)         PC 17599        35.64165
#&gt;   3:                              Heikkinen, Miss. Laina STON/O2. 3101282         7.92500
#&gt;   4:        Futrelle, Mrs. Jacques Heath (Lily May Peel)           113803        26.55000
#&gt;   5:                            Allen, Mr. William Henry           373450         8.05000
#&gt;  ---                                                                                     
#&gt; 887:                               Montvila, Rev. Juozas           211536        13.00000
#&gt; 888:                        Graham, Miss. Margaret Edith           112053        30.00000
#&gt; 889:            Johnston, Miss. Catherine Helen &quot;Carrie&quot;       W./C. 6607         5.86250
#&gt; 890:                               Behr, Mr. Karl Howell           111369        30.00000
#&gt; 891:                                 Dooley, Mr. Patrick           370376         7.75000
#&gt;      deck portside title   surname ticket_prefix
#&gt;   1: &lt;NA&gt;       NA    Mr    Braund           A/5
#&gt;   2:    C        1   Mrs   Cumings            PC
#&gt;   3: &lt;NA&gt;       NA  Miss Heikkinen       STON/O2
#&gt;   4:    C        1   Mrs  Futrelle          &lt;NA&gt;
#&gt;   5: &lt;NA&gt;       NA    Mr     Allen          &lt;NA&gt;
#&gt;  ---                                            
#&gt; 887: &lt;NA&gt;       NA   Rev  Montvila          &lt;NA&gt;
#&gt; 888:    B        0  Miss    Graham          &lt;NA&gt;
#&gt; 889: &lt;NA&gt;       NA  Miss  Johnston           W/C
#&gt; 890:    C        0    Mr      Behr          &lt;NA&gt;
#&gt; 891: &lt;NA&gt;       NA    Mr    Dooley          &lt;NA&gt;</code></pre>
<p>Now we can put everything together again, we concatenate our new <code>PipeOp</code> with the <code>Graph</code> created abve and use <code>PipeOpSelect</code> in order to de-select the <code>character</code> features we used for feature extraction. Additionally, we collapse the ‘surname’, so only surnames that make up more than 0.6 % of the data are kept.</p>
<p>The full graph we created is the following:</p>
<pre class="r"><code>gr_final = po_ftextract %&gt;&gt;%
  po(&quot;collapsefactors&quot;, param_vals = list(no_collapse_above_prevalence = 0.03)) %&gt;&gt;%
  po(&quot;select&quot;, param_vals = list(selector = selector_invert(selector_type(&quot;character&quot;)))) %&gt;&gt;%
  gunion(list(po_indicator, po(&quot;imputehist&quot;))) %&gt;&gt;%
  po(&quot;featureunion&quot;) %&gt;&gt;%
  po(&quot;fixfactors&quot;) %&gt;&gt;%
  po(&quot;imputenewlvl&quot;) %&gt;&gt;%
  po(learner)</code></pre>
<p>Let us see if things have improved:</p>
<pre class="r"><code>glrn = GraphLearner$new(gr_final)
res = resample(task, glrn, rdesc, store_models = TRUE)
agg = res$aggregate(msr(&quot;classif.acc&quot;))
agg
#&gt; classif.acc 
#&gt;   0.8282828</code></pre>
<p>We have improved a little bit! But there are many more things to explore! We could extract even more information from the different features and see what happens.</p>
</div>
<div id="future" class="section level2">
<h2>Future</h2>
<p>But now you are left to yourself! There are many <a href="https://www.kaggle.com/c/titanic">kaggle kernels</a> that treat the <strong>Titanic Dataset</strong> available. This can be a great starter to find even better models.</p>
</div>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" alt="Img link to Hugo website" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js"></script>



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/languages/r.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/languages/yaml.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="/js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
  </body>
</html>

