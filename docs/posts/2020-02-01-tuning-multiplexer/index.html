<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

  <!--radix_placeholder_meta_tags-->
<title>mlr3gallery: Tuning Over Multiple Learners</title>

<meta property="description" itemprop="description" content="This use case shows how to tune over multiple learners for a single task."/>

<link rel="canonical" href="https://mlr3gallery.mlr-org.com/posts/2020-02-01-tuning-multiplexer/"/>

<!--  https://schema.org/Article -->
<meta property="article:published" itemprop="datePublished" content="2020-02-01"/>
<meta property="article:created" itemprop="dateCreated" content="2020-02-01"/>
<meta name="article:author" content="Jakob Richter"/>
<meta name="article:author" content="Bernd Bischl"/>

<!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
<meta property="og:title" content="mlr3gallery: Tuning Over Multiple Learners"/>
<meta property="og:type" content="article"/>
<meta property="og:description" content="This use case shows how to tune over multiple learners for a single task."/>
<meta property="og:url" content="https://mlr3gallery.mlr-org.com/posts/2020-02-01-tuning-multiplexer/"/>
<meta property="og:image" content="https://mlr3gallery.mlr-org.com/posts/2020-02-01-tuning-multiplexer/2020-02-01-tuning-multiplexer_files/figure-html5/unnamed-chunk-4-1.png"/>
<meta property="og:image:width" content="1248"/>
<meta property="og:image:height" content="768"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:site_name" content="mlr3gallery"/>

<!--  https://dev.twitter.com/cards/types/summary -->
<meta property="twitter:card" content="summary_large_image"/>
<meta property="twitter:title" content="mlr3gallery: Tuning Over Multiple Learners"/>
<meta property="twitter:description" content="This use case shows how to tune over multiple learners for a single task."/>
<meta property="twitter:url" content="https://mlr3gallery.mlr-org.com/posts/2020-02-01-tuning-multiplexer/"/>
<meta property="twitter:image" content="https://mlr3gallery.mlr-org.com/posts/2020-02-01-tuning-multiplexer/2020-02-01-tuning-multiplexer_files/figure-html5/unnamed-chunk-4-1.png"/>
<meta property="twitter:image:width" content="1248"/>
<meta property="twitter:image:height" content="768"/>

<!--  https://scholar.google.com/intl/en/scholar/inclusion.html#indexing -->
<meta name="citation_title" content="mlr3gallery: Tuning Over Multiple Learners"/>
<meta name="citation_fulltext_html_url" content="https://mlr3gallery.mlr-org.com/posts/2020-02-01-tuning-multiplexer/"/>
<meta name="citation_online_date" content="2020/02/01"/>
<meta name="citation_publication_date" content="2020/02/01"/>
<meta name="citation_author" content="Jakob Richter"/>
<meta name="citation_author" content="Bernd Bischl"/>
<!--/radix_placeholder_meta_tags-->
  <!--radix_placeholder_rmarkdown_metadata-->

<script type="text/json" id="radix-rmarkdown-metadata">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","categories","author","date","description","output","citation_url","canonical_url"]}},"value":[{"type":"character","attributes":{},"value":["Tuning Over Multiple Learners"]},{"type":"character","attributes":{},"value":["tuning"]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name"]}},"value":[{"type":"character","attributes":{},"value":["Jakob Richter"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name"]}},"value":[{"type":"character","attributes":{},"value":["Bernd Bischl"]}]}]},{"type":"character","attributes":{},"value":["02-01-2020"]},{"type":"character","attributes":{},"value":["This use case shows how to tune over multiple learners for a single task."]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained","css"]}},"value":[{"type":"logical","attributes":{},"value":[false]},{"type":"character","attributes":{},"value":["../../custom.css"]}]}]},{"type":"character","attributes":{},"value":["https://mlr3gallery.mlr-org.com/posts/2020-02-01-tuning-multiplexer/"]},{"type":"character","attributes":{},"value":["https://mlr3gallery.mlr-org.com/posts/2020-02-01-tuning-multiplexer/"]}]}
</script>
<!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["2020-02-01-tuning-multiplexer_files/figure-html5/unnamed-chunk-11-1.png","2020-02-01-tuning-multiplexer_files/figure-html5/unnamed-chunk-4-1.png"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->

<script type="application/javascript">

  window.headroom_prevent_pin = false;

  window.document.addEventListener("DOMContentLoaded", function (event) {

    // initialize headroom for banner
    var header = $('header').get(0);
    var headerHeight = header.offsetHeight;
    var headroom = new Headroom(header, {
      onPin : function() {
        if (window.headroom_prevent_pin) {
          window.headroom_prevent_pin = false;
          headroom.unpin();
        }
      }
    });
    headroom.init();
    if(window.location.hash)
      headroom.unpin();
    $(header).addClass('headroom--transition');

    // offset scroll location for banner on hash change
    // (see: https://github.com/WickyNilliams/headroom.js/issues/38)
    window.addEventListener("hashchange", function(event) {
      window.scrollTo(0, window.pageYOffset - (headerHeight + 25));
    });

    // responsive menu
    $('.distill-site-header').each(function(i, val) {
      var topnav = $(this);
      var toggle = topnav.find('.nav-toggle');
      toggle.on('click', function() {
        topnav.toggleClass('responsive');
      });
    });

    // nav dropdowns
    $('.nav-dropbtn').click(function(e) {
      $(this).next('.nav-dropdown-content').toggleClass('nav-dropdown-active');
      $(this).parent().siblings('.nav-dropdown')
         .children('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $("body").click(function(e){
      $('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $(".nav-dropdown").click(function(e){
      e.stopPropagation();
    });
  });
</script>

<style type="text/css">

/* Theme (user-documented overrideables for nav appearance) */

.distill-site-nav {
  color: rgba(255, 255, 255, 0.8);
  background-color: #455a64;
  font-size: 15px;
  font-weight: 300;
}

.distill-site-nav a {
  color: inherit;
  text-decoration: none;
}

.distill-site-nav a:hover {
  color: white;
}

@media print {
  .distill-site-nav {
    display: none;
  }
}

.distill-site-header {

}

.distill-site-footer {

}


/* Site Header */

.distill-site-header {
  width: 100%;
  box-sizing: border-box;
  z-index: 3;
}

.distill-site-header .nav-left {
  display: inline-block;
  margin-left: 8px;
}

@media screen and (max-width: 768px) {
  .distill-site-header .nav-left {
    margin-left: 0;
  }
}


.distill-site-header .nav-right {
  float: right;
  margin-right: 8px;
}

.distill-site-header a,
.distill-site-header .title {
  display: inline-block;
  text-align: center;
  padding: 14px 10px 14px 10px;
}

.distill-site-header .title {
  font-size: 18px;
}

.distill-site-header .logo {
  padding: 0;
}

.distill-site-header .logo img {
  display: none;
  max-height: 20px;
  width: auto;
  margin-bottom: -4px;
}

.distill-site-header .nav-image img {
  max-height: 18px;
  width: auto;
  display: inline-block;
  margin-bottom: -3px;
}



@media screen and (min-width: 1000px) {
  .distill-site-header .logo img {
    display: inline-block;
  }
  .distill-site-header .nav-left {
    margin-left: 20px;
  }
  .distill-site-header .nav-right {
    margin-right: 20px;
  }
  .distill-site-header .title {
    padding-left: 12px;
  }
}


.distill-site-header .nav-toggle {
  display: none;
}

.nav-dropdown {
  display: inline-block;
  position: relative;
}

.nav-dropdown .nav-dropbtn {
  border: none;
  outline: none;
  color: rgba(255, 255, 255, 0.8);
  padding: 16px 10px;
  background-color: transparent;
  font-family: inherit;
  font-size: inherit;
  font-weight: inherit;
  margin: 0;
  margin-top: 1px;
  z-index: 2;
}

.nav-dropdown-content {
  display: none;
  position: absolute;
  background-color: white;
  min-width: 200px;
  border: 1px solid rgba(0,0,0,0.15);
  border-radius: 4px;
  box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.1);
  z-index: 1;
  margin-top: 2px;
  white-space: nowrap;
  padding-top: 4px;
  padding-bottom: 4px;
}

.nav-dropdown-content hr {
  margin-top: 4px;
  margin-bottom: 4px;
  border: none;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.nav-dropdown-active {
  display: block;
}

.nav-dropdown-content a, .nav-dropdown-content .nav-dropdown-header {
  color: black;
  padding: 6px 24px;
  text-decoration: none;
  display: block;
  text-align: left;
}

.nav-dropdown-content .nav-dropdown-header {
  display: block;
  padding: 5px 24px;
  padding-bottom: 0;
  text-transform: uppercase;
  font-size: 14px;
  color: #999999;
  white-space: nowrap;
}

.nav-dropdown:hover .nav-dropbtn {
  color: white;
}

.nav-dropdown-content a:hover {
  background-color: #ddd;
  color: black;
}

.nav-right .nav-dropdown-content {
  margin-left: -45%;
  right: 0;
}

@media screen and (max-width: 768px) {
  .distill-site-header a, .distill-site-header .nav-dropdown  {display: none;}
  .distill-site-header a.nav-toggle {
    float: right;
    display: block;
  }
  .distill-site-header .title {
    margin-left: 0;
  }
  .distill-site-header .nav-right {
    margin-right: 0;
  }
  .distill-site-header {
    overflow: hidden;
  }
  .nav-right .nav-dropdown-content {
    margin-left: 0;
  }
}


@media screen and (max-width: 768px) {
  .distill-site-header.responsive {position: relative;}
  .distill-site-header.responsive a.nav-toggle {
    position: absolute;
    right: 0;
    top: 0;
  }
  .distill-site-header.responsive a,
  .distill-site-header.responsive .nav-dropdown {
    display: block;
    text-align: left;
  }
  .distill-site-header.responsive .nav-left,
  .distill-site-header.responsive .nav-right {
    width: 100%;
  }
  .distill-site-header.responsive .nav-dropdown {float: none;}
  .distill-site-header.responsive .nav-dropdown-content {position: relative;}
  .distill-site-header.responsive .nav-dropdown .nav-dropbtn {
    display: block;
    width: 100%;
    text-align: left;
  }
}

/* Site Footer */

.distill-site-footer {
  width: 100%;
  overflow: hidden;
  box-sizing: border-box;
  z-index: 3;
  margin-top: 30px;
  padding-top: 30px;
  padding-bottom: 30px;
  text-align: center;
}

/* Headroom */

d-title {
  padding-top: 6rem;
}

@media print {
  d-title {
    padding-top: 4rem;
  }
}

.headroom {
  z-index: 1000;
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
}

.headroom--transition {
  transition: all .4s ease-in-out;
}

.headroom--unpinned {
  top: -100px;
}

.headroom--pinned {
  top: 0;
}

</style>

<link href="../../site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet"/>
<link href="../../site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet"/>
<script src="../../site_libs/headroom-0.9.4/headroom.min.js"></script>
<!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->

<style type="text/css">

body {
  background-color: white;
}

.pandoc-table {
  width: 100%;
}

.pandoc-table>caption {
  margin-bottom: 10px;
}

.pandoc-table th:not([align]) {
  text-align: left;
}

.pagedtable-footer {
  font-size: 15px;
}

.html-widget {
  margin-bottom: 2.0em;
}

.l-screen-inset {
  padding-right: 16px;
}

.l-screen .caption {
  margin-left: 10px;
}

.shaded {
  background: rgb(247, 247, 247);
  padding-top: 20px;
  padding-bottom: 20px;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .html-widget {
  margin-bottom: 0;
  border: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .shaded-content {
  background: white;
}

.text-output {
  margin-top: 0;
  line-height: 1.5em;
}

.hidden {
  display: none !important;
}

d-article {
  padding-bottom: 30px;
}

d-appendix {
  padding-top: 30px;
}

d-article>p>img {
  width: 100%;
}

d-article iframe {
  border: 1px solid rgba(0, 0, 0, 0.1);
  margin-bottom: 2.0em;
  width: 100%;
}

figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

/* CSS for table of contents */

.d-toc {
  color: rgba(0,0,0,0.8);
  font-size: 0.8em;
  line-height: 1em;
}

.d-toc-header {
  font-size: 0.6rem;
  font-weight: 400;
  color: rgba(0, 0, 0, 0.5);
  text-transform: uppercase;
  margin-top: 0;
  margin-bottom: 1.3em;
}

.d-toc a {
  border-bottom: none;
}

.d-toc ul {
  padding-left: 0;
}

.d-toc li>ul {
  padding-top: 0.8em;
  padding-left: 16px;
  margin-bottom: 0.6em;
}

.d-toc ul,
.d-toc li {
  list-style-type: none;
}

.d-toc li {
  margin-bottom: 0.9em;
}

.d-toc-separator {
  margin-top: 20px;
  margin-bottom: 2em;
}

.d-article-with-toc {
  border-top: none;
  padding-top: 0;
}



/* Tweak code blocks (note that this CSS is repeated above in an injection
   into the d-code shadow dom) */

d-code {
  overflow-x: auto !important;
}

pre.d-code code.d-code {
  padding-left: 10px;
  font-size: 12px;
  border-left: 2px solid rgba(0,0,0,0.1);
}

pre.text-output {

  font-size: 12px;
  color: black;
  background: none;
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

@media(min-width: 768px) {

d-code {
  overflow-x: visible !important;
}

pre.d-code code.d-code  {
    padding-left: 18px;
    font-size: 14px;
}
pre.text-output {
  font-size: 14px;
}
}

/* Figure */

.figure {
  position: relative;
  margin-bottom: 2.5em;
  margin-top: 1.5em;
}

.figure img {
  width: 100%;
}

.figure .caption {
  color: rgba(0, 0, 0, 0.6);
  font-size: 12px;
  line-height: 1.5em;
}

.figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

.figure .caption a {
  color: rgba(0, 0, 0, 0.6);
}

.figure .caption b,
.figure .caption strong, {
  font-weight: 600;
  color: rgba(0, 0, 0, 1.0);
}



/* Tweak 1000px media break to show more text */

@media(min-width: 1000px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 16px;
  }

  .grid {
    grid-column-gap: 16px;
  }

  d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
  }
  figure .caption, .figure .caption, figure figcaption {
    font-size: 13px;
  }
}

@media(min-width: 1180px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 32px;
  }

  .grid {
    grid-column-gap: 32px;
  }
}


/* Get the citation styles for the appendix (not auto-injected on render since
   we do our own rendering of the citation appendix) */

d-appendix .citation-appendix,
.d-appendix .citation-appendix {
  font-size: 11px;
  line-height: 15px;
  border-left: 1px solid rgba(0, 0, 0, 0.1);
  padding-left: 18px;
  border: 1px solid rgba(0,0,0,0.1);
  background: rgba(0, 0, 0, 0.02);
  padding: 10px 18px;
  border-radius: 3px;
  color: rgba(150, 150, 150, 1);
  overflow: hidden;
  margin-top: -12px;
  white-space: pre-wrap;
  word-wrap: break-word;
}


/* Social footer */

.social_footer {
  margin-top: 30px;
  margin-bottom: 0;
  color: rgba(0,0,0,0.67);
}

.disqus-comments {
  margin-right: 30px;
}

.disqus-comment-count {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  cursor: pointer;
}

#disqus_thread {
  margin-top: 30px;
}

.article-sharing a {
  border-bottom: none;
  margin-right: 8px;
}

.article-sharing a:hover {
  border-bottom: none;
}

.sidebar-section.subscribe {
  font-size: 12px;
  line-height: 1.6em;
}

.subscribe p {
  margin-bottom: 0.5em;
}


.article-footer .subscribe {
  font-size: 15px;
  margin-top: 45px;
}


.sidebar-section.custom {
  font-size: 12px;
  line-height: 1.6em;
}

.custom p {
  margin-bottom: 0.5em;
}


/* Improve display for browsers without grid (IE/Edge <= 15) */

.downlevel {
  line-height: 1.6em;
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  margin: 0;
}

.downlevel .d-title {
  padding-top: 6rem;
  padding-bottom: 1.5rem;
}

.downlevel .d-title h1 {
  font-size: 50px;
  font-weight: 700;
  line-height: 1.1em;
  margin: 0 0 0.5rem;
}

.downlevel .d-title p {
  font-weight: 300;
  font-size: 1.2rem;
  line-height: 1.55em;
  margin-top: 0;
}

.downlevel .d-byline {
  padding-top: 0.8em;
  padding-bottom: 0.8em;
  font-size: 0.8rem;
  line-height: 1.8em;
}

.downlevel .section-separator {
  border: none;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
}

.downlevel .d-article {
  font-size: 1.06rem;
  line-height: 1.7em;
  padding-top: 1rem;
  padding-bottom: 2rem;
}


.downlevel .d-appendix {
  padding-left: 0;
  padding-right: 0;
  max-width: none;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.5);
  padding-top: 40px;
  padding-bottom: 48px;
}

.downlevel .footnotes ol {
  padding-left: 13px;
}

.downlevel .base-grid,
.downlevel .distill-header,
.downlevel .d-title,
.downlevel .d-abstract,
.downlevel .d-article,
.downlevel .d-appendix,
.downlevel .distill-appendix,
.downlevel .d-byline,
.downlevel .d-footnote-list,
.downlevel .d-citation-list,
.downlevel .distill-footer,
.downlevel .appendix-bottom,
.downlevel .posts-container {
  padding-left: 40px;
  padding-right: 40px;
}

@media(min-width: 768px) {
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
  padding-left: 150px;
  padding-right: 150px;
  max-width: 900px;
}
}

.downlevel pre code {
  display: block;
  border-left: 2px solid rgba(0, 0, 0, .1);
  padding: 0 0 0 20px;
  font-size: 14px;
}

.downlevel code, .downlevel pre {
  color: black;
  background: none;
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

</style>

<script type="application/javascript">

function is_downlevel_browser() {
  if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                 window.navigator.userAgent)) {
    return true;
  } else {
    return window.load_distill_framework === undefined;
  }
}

// show body when load is complete
function on_load_complete() {

  // set body to visible
  document.body.style.visibility = 'visible';

  // force redraw for leaflet widgets
  if (window.HTMLWidgets) {
    var maps = window.HTMLWidgets.findAll(".leaflet");
    $.each(maps, function(i, el) {
      var map = this.getMap();
      map.invalidateSize();
      map.eachLayer(function(layer) {
        if (layer instanceof L.TileLayer)
          layer.redraw();
      });
    });
  }

  // trigger 'shown' so htmlwidgets resize
  $('d-article').trigger('shown');
}

function init_distill() {

  init_common();

  // create front matter
  var front_matter = $('<d-front-matter></d-front-matter>');
  $('#distill-front-matter').wrap(front_matter);

  // create d-title
  $('.d-title').changeElementType('d-title');

  // create d-byline
  var byline = $('<d-byline></d-byline>');
  $('.d-byline').replaceWith(byline);

  // create d-article
  var article = $('<d-article></d-article>');
  $('.d-article').wrap(article).children().unwrap();

  // move posts container into article
  $('.posts-container').appendTo($('d-article'));

  // create d-appendix
  $('.d-appendix').changeElementType('d-appendix');

  // create d-bibliography
  var bibliography = $('<d-bibliography></d-bibliography>');
  $('#distill-bibliography').wrap(bibliography);

  // flag indicating that we have appendix items
  var appendix = $('.appendix-bottom').children('h3').length > 0;

  // replace citations with <d-cite>
  $('.citation').each(function(i, val) {
    appendix = true;
    var cites = $(this).attr('data-cites').split(" ");
    var dt_cite = $('<d-cite></d-cite>');
    dt_cite.attr('key', cites.join());
    $(this).replaceWith(dt_cite);
  });
  // remove refs
  $('#refs').remove();

  // replace footnotes with <d-footnote>
  $('.footnote-ref').each(function(i, val) {
    appendix = true;
    var href = $(this).attr('href');
    var id = href.replace('#', '');
    var fn = $('#' + id);
    var fn_p = $('#' + id + '>p');
    fn_p.find('.footnote-back').remove();
    var text = fn_p.html();
    var dtfn = $('<d-footnote></d-footnote>');
    dtfn.html(text);
    $(this).replaceWith(dtfn);
  });
  // remove footnotes
  $('.footnotes').remove();

  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    var id = $(this).attr('id');
    $('.d-toc a[href="#' + id + '"]').parent().remove();
    appendix = true;
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
  });

  // show d-appendix if we have appendix content
  $("d-appendix").css('display', appendix ? 'grid' : 'none');

  // replace code blocks with d-code
  $('pre>code').each(function(i, val) {
    var code = $(this);
    var pre = code.parent();
    var clz = "";
    var language = pre.attr('class');
    if (language) {
      // map unknown languages to "clike" (without this they just dissapear)
      if ($.inArray(language, ["bash", "clike", "css", "go", "html",
                               "javascript", "js", "julia", "lua", "markdown",
                               "markup", "mathml", "python", "svg", "xml"]) == -1)
        language = "clike";
      language = ' language="' + language + '"';
      var dt_code = $('<d-code block' + language + clz + '></d-code>');
      dt_code.text(code.text());
      pre.replaceWith(dt_code);
    } else {
      code.addClass('text-output').unwrap().changeElementType('pre');
    }
  });

  // localize layout chunks to just output
  $('.layout-chunk').each(function(i, val) {

    // capture layout
    var layout = $(this).attr('data-layout');

    // apply layout to markdown level block elements
    var elements = $(this).children().not('d-code, pre.text-output, script');
    elements.each(function(i, el) {
      var layout_div = $('<div class="' + layout + '"></div>');
      if (layout_div.hasClass('shaded')) {
        var shaded_content = $('<div class="shaded-content"></div>');
        $(this).wrap(shaded_content);
        $(this).parent().wrap(layout_div);
      } else {
        $(this).wrap(layout_div);
      }
    });


    // unwrap the layout-chunk div
    $(this).children().unwrap();
  });

  // load distill framework
  load_distill_framework();

  // wait for window.distillRunlevel == 4 to do post processing
  function distill_post_process() {

    if (!window.distillRunlevel || window.distillRunlevel < 4)
      return;

    // hide author/affiliations entirely if we have no authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
    if (!have_authors)
      $('d-byline').addClass('hidden');

    // table of contents
    if (have_authors) // adjust border if we are in authors
      $('.d-toc').parent().addClass('d-article-with-toc');

    // strip links that point to #
    $('.authors-affiliations').find('a[href="#"]').removeAttr('href');

    // hide elements of author/affiliations grid that have no value
    function hide_byline_column(caption) {
      $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
    }

    // affiliations
    var have_affiliations = false;
    for (var i = 0; i<front_matter.authors.length; ++i) {
      var author = front_matter.authors[i];
      if (author.affiliation !== "&nbsp;") {
        have_affiliations = true;
        break;
      }
    }
    if (!have_affiliations)
      $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');

    // published date
    if (!front_matter.publishedDate)
      hide_byline_column("Published");

    // document object identifier
    var doi = $('d-byline').find('h3:contains("DOI")');
    var doi_p = doi.next().empty();
    if (!front_matter.doi) {
      // if we have a citation and valid citationText then link to that
      if ($('#citation').length > 0 && front_matter.citationText) {
        doi.html('Citation');
        $('<a href="#citation"></a>')
          .text(front_matter.citationText)
          .appendTo(doi_p);
      } else {
        hide_byline_column("DOI");
      }
    } else {
      $('<a></a>')
         .attr('href', "https://doi.org/" + front_matter.doi)
         .html(front_matter.doi)
         .appendTo(doi_p);
    }

     // change plural form of authors/affiliations
    if (front_matter.authors.length === 1) {
      var grid = $('.authors-affiliations');
      grid.children('h3:contains("Authors")').text('Author');
      grid.children('h3:contains("Affiliations")').text('Affiliation');
    }

    // inject pre code styles (can't do this with a global stylesheet b/c a shadow root is used)
    $('d-code').each(function(i, val) {
      var style = document.createElement('style');
      style.innerHTML = 'pre code { padding-left: 10px; font-size: 12px; border-left: 2px solid rgba(0,0,0,0.1); } ' +
                        '@media(min-width: 768px) { pre code { padding-left: 18px; font-size: 14px; } }';
      if (this.shadowRoot)
        this.shadowRoot.appendChild(style);
    });

    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
    $('.appendix-bottom').remove();

    // clear polling timer
    clearInterval(tid);

    // show body now that everything is ready
    on_load_complete();
  }

  var tid = setInterval(distill_post_process, 50);
  distill_post_process();

}

function init_downlevel() {

  init_common();

   // insert hr after d-title
  $('.d-title').after($('<hr class="section-separator"/>'));

  // check if we have authors
  var front_matter = JSON.parse($("#distill-front-matter").html());
  var have_authors = front_matter.authors && front_matter.authors.length > 0;

  // manage byline/border
  if (!have_authors)
    $('.d-byline').remove();
  $('.d-byline').after($('<hr class="section-separator"/>'));
  $('.d-byline a').remove();

  // remove toc
  $('.d-toc-header').remove();
  $('.d-toc').remove();
  $('.d-toc-separator').remove();

  // move appendix elements
  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
  });


  // inject headers into references and footnotes
  var refs_header = $('<h3></h3>');
  refs_header.text('References');
  $('#refs').prepend(refs_header);

  var footnotes_header = $('<h3></h3');
  footnotes_header.text('Footnotes');
  $('.footnotes').children('hr').first().replaceWith(footnotes_header);

  // move appendix-bottom entries to the bottom
  $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
  $('.appendix-bottom').remove();

  // remove appendix if it's empty
  if ($('.d-appendix').children().length === 0)
    $('.d-appendix').remove();

  // prepend separator above appendix
  $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));

  // trim code
  $('pre>code').each(function(i, val) {
    $(this).html($.trim($(this).html()));
  });

  // move posts-container right before article
  $('.posts-container').insertBefore($('.d-article'));

  $('body').addClass('downlevel');

  on_load_complete();
}


function init_common() {

  // jquery plugin to change element types
  (function($) {
    $.fn.changeElementType = function(newType) {
      var attrs = {};

      $.each(this[0].attributes, function(idx, attr) {
        attrs[attr.nodeName] = attr.nodeValue;
      });

      this.replaceWith(function() {
        return $("<" + newType + "/>", attrs).append($(this).contents());
      });
    };
  })(jQuery);

  // prevent underline for linked images
  $('a > img').parent().css({'border-bottom' : 'none'});

  // mark non-body figures created by knitr chunks as 100% width
  $('.layout-chunk').each(function(i, val) {
    var figures = $(this).find('img, .html-widget');
    if ($(this).attr('data-layout') !== "l-body") {
      figures.css('width', '100%');
    } else {
      figures.css('max-width', '100%');
      figures.filter("[width]").each(function(i, val) {
        var fig = $(this);
        fig.css('width', fig.attr('width') + 'px');
      });

    }
  });

  // auto-append index.html to post-preview links in file: protocol
  // and in rstudio ide preview
  $('.post-preview').each(function(i, val) {
    if (window.location.protocol === "file:")
      $(this).attr('href', $(this).attr('href') + "index.html");
  });

  // get rid of index.html references in header
  if (window.location.protocol !== "file:") {
    $('.distill-site-header a[href]').each(function(i,val) {
      $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
    });
  }

  // add class to pandoc style tables
  $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
  $('.kable-table').children('table').addClass('pandoc-table');

  // add figcaption style to table captions
  $('caption').parent('table').addClass("figcaption");

  // initialize posts list
  if (window.init_posts_list)
    window.init_posts_list();

  // implmement disqus comment link
  $('.disqus-comment-count').click(function() {
    window.headroom_prevent_pin = true;
    $('#disqus_thread').toggleClass('hidden');
    if (!$('#disqus_thread').hasClass('hidden')) {
      var offset = $(this).offset();
      $(window).resize();
      $('html, body').animate({
        scrollTop: offset.top - 35
      });
    }
  });
}

document.addEventListener('DOMContentLoaded', function() {
  if (is_downlevel_browser())
    init_downlevel();
  else
    window.addEventListener('WebComponentsReady', init_distill);
});

</script>

<!--/radix_placeholder_distill-->
  <script src="../../site_libs/jquery-1.11.3/jquery.min.js"></script>
  <script src="../../site_libs/bowser-1.9.3/bowser.min.js"></script>
  <script src="../../site_libs/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="../../site_libs/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
<!--/radix_placeholder_site_in_header-->

  <link rel="stylesheet" href="../../custom.css" type="text/css"/>

</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"Tuning Over Multiple Learners","description":"This use case shows how to tune over multiple learners for a single task.","authors":[{"author":"Jakob Richter","authorURL":"#","affiliation":"&nbsp;","affiliationURL":"#"},{"author":"Bernd Bischl","authorURL":"#","affiliation":"&nbsp;","affiliationURL":"#"}],"publishedDate":"2020-02-01T00:00:00.000+00:00","citationText":"Richter & Bischl, 2020"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<header class="header header--fixed" role="banner">
<nav class="distill-site-nav distill-site-header">
<div class="nav-left">
<a class="logo" href="https://mlr3.mlr-org.com">
<img src="../../images/logo.png" alt="Logo"/>
</a>
<a href="../../index.html" class="title">mlr3gallery</a>
</div>
<div class="nav-right">
<a href="https://github.com/mlr-org/mlr3gallery">
<i class="fab fa-github" aria-hidden="true"></i>
</a>
<a href="javascript:void(0);" class="nav-toggle">&#9776;</a>
</div>
</nav>
</header>
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>Tuning Over Multiple Learners</h1>
<p><p>This use case shows how to tune over multiple learners for a single task.</p></p>
</div>

<div class="d-byline">
  Jakob Richter  
  
,   Bernd Bischl  
  
<br/>02-01-2020
</div>

<div class="d-article">
<p>This use case shows how to tune over multiple learners for a single task. You will learn the following:</p>
<ul>
<li>Build a pipeline that can switch between multiple learners</li>
<li>Define the hyperparameter search space for the pipeline</li>
<li>Run a random or grid search (or any other tuner, always works the same)</li>
<li>Run nested resampling for unbiased performance estimates</li>
</ul>
<p>This is an advanced use case. What should you know before:</p>
<ul>
<li><a href="https://mlr3.mlr-org.com">mlr3</a> basics</li>
<li><a href="https://mlr3tuning.mlr-org.com">mlr3tuning</a> basics, especially <a href="https://mlr3tuning.mlr-org.com/reference/AutoTuner.html"><code>AutoTuner</code></a></li>
<li><a href="https://mlr3pipelines.mlr-org.com">mlr3pipelines</a>, especially branching</li>
</ul>
<h2 id="the-setup">The Setup</h2>
<p>Assume, you are given some ML task and what to compare a couple of learners, probably because you want to select the best of them at the end of the analysis. That’s a super standard scenario, it actually sounds so common that you might wonder: Why an (advanced) blog post about this? With pipelines? We will consider 2 cases: (a) Running the learners in their default, so without tuning, and (b) with tuning.</p>
<p>Let’s load some packages and define our learners.</p>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
set.seed(1)
library(mlr3)
library(mlr3tuning)
library(mlr3pipelines)
library(mlr3learners)
library(paradox)
lgr::get_logger(&quot;mlr3&quot;)$set_threshold(&quot;warn&quot;)
lgr::get_logger(&quot;mlr3tuning&quot;)$set_threshold(&quot;warn&quot;)

learns = list(
  lrn(&quot;classif.xgboost&quot;, id = &quot;xgb&quot;),
  lrn(&quot;classif.ranger&quot;, id = &quot;rf&quot;)
)
learns_ids = sapply(learns, function(x) x$id)

task = tsk(&quot;sonar&quot;) # some random data for this demo
cv1 = rsmp(&quot;cv&quot;, folds = 2) # inner loop for nested CV
cv2 = rsmp(&quot;cv&quot;, folds = 5) # outer loop for nested CV</code></pre>
</div>
<h2 id="default-parameters">Default Parameters</h2>
<h3 id="the-benchmark-table-approach">The Benchmark-Table Approach</h3>
<p>Assume we don’t want to perform tuning and or with running all learner in their respective defaults. Simply run benchmark on the learners and the tasks. That tabulates our results nicely and shows us what works best.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
bg = benchmark_grid(task, learns, cv2)
b = benchmark(bg)
b$aggregate(measures = msr(&quot;classif.ce&quot;))</code></pre>
<pre><code>
   nr      resample_result task_id learner_id resampling_id iters classif.ce
1:  1 &lt;ResampleResult[18]&gt;   sonar        xgb            cv     5  0.2743322
2:  2 &lt;ResampleResult[18]&gt;   sonar         rf            cv     5  0.1728223</code></pre>
</div>
<h3 id="the-pipelines-approach">The Pipelines Approach</h3>
<p>Ok, why would we ever want to change the simple approach above - and use pipelines / tuning for this? Three reasons:</p>
<ol type="1">
<li>What we are doing with <a href="https://mlr3.mlr-org.com/reference/benchmark.html"><code>benchmark</code></a> is actually statistically flawed, insofar if we report the error of the numerically best method from the benchmark table as its estimated future performance. If we do that we have “optimized on the CV” (we basically ran a grid search over our learners!) and we know that this is will produce optimistically biased results. NB: This is a somewhat ridiculous criticism if we are going over only a handful of options, and the bias will be very small. But it will be noticeable if we do this over hundreds of learners, so it is important to understand the underlying problem. This is a somewhat subtle point, and this gallery post is more about technical hints for <code>mlr3</code>, so we will stop this discussion here.</li>
<li>For some tuning algorithms, you might have a chance to more efficiently select from the set of algorithms than running the full benchmark. Because of the categorical nature of the problem, you will not be able to learn stuff like “If learner A works bad, I don’t have to try learner B”, but you can potentially save some resampling iterations. Assume you have so select from 100 candidates, experiments are expensive, and you use a 20-fold CV. If learner A has super-bad results in the first 5 folds of the CV, you might already want to stop here. “Racing” would be such a tuning algorithm.</li>
<li>It helps us to foreshadow what comes later in this post where we tune the learners.</li>
</ol>
<p>The pipeline just has a single purpose in this example: It should allow us to switch between different learners, depending on a hyperparameter. The pipe consists of three elements:</p>
<ul>
<li><a href="https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_branch.html"><code>branch</code></a> pipes incoming data to one of the following elements, on different data channels. We can name these channel on construction with <code>options</code>.</li>
<li>our learners (combined with <a href="https://mlr3pipelines.mlr-org.com/reference/gunion.html"><code>gunion</code></a>)</li>
<li><a href="https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_unbranch.html"><code>unbranch</code></a> combines the forked paths at the end.</li>
</ul>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
pipe =
  po(&quot;branch&quot;, options = learns_ids) %&gt;&gt;%
  gunion(lapply(learns, po)) %&gt;&gt;%
  po(&quot;unbranch&quot;)
pipe$plot()</code></pre>
<p><img src="2020-02-01-tuning-multiplexer_files/figure-html5/unnamed-chunk-4-1.png" width="624" /></p>
</div>
<p>The pipeline has now quite a lot of available hyperparameters. It includes all hyperparameters from all contained learners. But as we don’t tune them here (yet), we don’t care (yet). But the first hyperparameter is special. <code>branch.selection</code> controls over which (named) branching channel our data flows.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
pipe$param_set$ids()</code></pre>
<pre><code>
 [1] &quot;branch.selection&quot;                &quot;xgb.booster&quot;                    
 [3] &quot;xgb.watchlist&quot;                   &quot;xgb.eta&quot;                        
 [5] &quot;xgb.gamma&quot;                       &quot;xgb.max_depth&quot;                  
 [7] &quot;xgb.min_child_weight&quot;            &quot;xgb.subsample&quot;                  
 [9] &quot;xgb.colsample_bytree&quot;            &quot;xgb.colsample_bylevel&quot;          
[11] &quot;xgb.colsample_bynode&quot;            &quot;xgb.num_parallel_tree&quot;          
[13] &quot;xgb.lambda&quot;                      &quot;xgb.lambda_bias&quot;                
[15] &quot;xgb.alpha&quot;                       &quot;xgb.objective&quot;                  
[17] &quot;xgb.eval_metric&quot;                 &quot;xgb.base_score&quot;                 
[19] &quot;xgb.max_delta_step&quot;              &quot;xgb.missing&quot;                    
[21] &quot;xgb.monotone_constraints&quot;        &quot;xgb.tweedie_variance_power&quot;     
[23] &quot;xgb.nthread&quot;                     &quot;xgb.nrounds&quot;                    
[25] &quot;xgb.feval&quot;                       &quot;xgb.verbose&quot;                    
[27] &quot;xgb.print_every_n&quot;               &quot;xgb.early_stopping_rounds&quot;      
[29] &quot;xgb.maximize&quot;                    &quot;xgb.sample_type&quot;                
[31] &quot;xgb.normalize_type&quot;              &quot;xgb.rate_drop&quot;                  
[33] &quot;xgb.skip_drop&quot;                   &quot;xgb.one_drop&quot;                   
[35] &quot;xgb.tree_method&quot;                 &quot;xgb.grow_policy&quot;                
[37] &quot;xgb.max_leaves&quot;                  &quot;xgb.max_bin&quot;                    
[39] &quot;xgb.callbacks&quot;                   &quot;xgb.sketch_eps&quot;                 
[41] &quot;xgb.scale_pos_weight&quot;            &quot;xgb.updater&quot;                    
[43] &quot;xgb.refresh_leaf&quot;                &quot;xgb.feature_selector&quot;           
[45] &quot;xgb.top_k&quot;                       &quot;xgb.predictor&quot;                  
[47] &quot;xgb.save_period&quot;                 &quot;xgb.save_name&quot;                  
[49] &quot;xgb.xgb_model&quot;                   &quot;xgb.interaction_constraints&quot;    
[51] &quot;xgb.outputmargin&quot;                &quot;xgb.ntreelimit&quot;                 
[53] &quot;xgb.predleaf&quot;                    &quot;xgb.predcontrib&quot;                
[55] &quot;xgb.approxcontrib&quot;               &quot;xgb.predinteraction&quot;            
[57] &quot;xgb.reshape&quot;                     &quot;xgb.training&quot;                   
[59] &quot;rf.num.trees&quot;                    &quot;rf.mtry&quot;                        
[61] &quot;rf.importance&quot;                   &quot;rf.write.forest&quot;                
[63] &quot;rf.min.node.size&quot;                &quot;rf.replace&quot;                     
[65] &quot;rf.sample.fraction&quot;              &quot;rf.class.weights&quot;               
[67] &quot;rf.splitrule&quot;                    &quot;rf.num.random.splits&quot;           
[69] &quot;rf.split.select.weights&quot;         &quot;rf.always.split.variables&quot;      
[71] &quot;rf.respect.unordered.factors&quot;    &quot;rf.scale.permutation.importance&quot;
[73] &quot;rf.keep.inbag&quot;                   &quot;rf.holdout&quot;                     
[75] &quot;rf.num.threads&quot;                  &quot;rf.save.memory&quot;                 
[77] &quot;rf.verbose&quot;                      &quot;rf.oob.error&quot;                   
[79] &quot;rf.max.depth&quot;                    &quot;rf.alpha&quot;                       
[81] &quot;rf.min.prop&quot;                     &quot;rf.regularization.factor&quot;       
[83] &quot;rf.regularization.usedepth&quot;      &quot;rf.seed&quot;                        
[85] &quot;rf.minprop&quot;                      &quot;rf.predict.all&quot;                 
[87] &quot;rf.se.method&quot;                   </code></pre>
<pre class="r"><code>
pipe$param_set$params$branch.selection</code></pre>
<pre><code>
                 id    class lower upper levels        default
1: branch.selection ParamFct    NA    NA xgb,rf &lt;NoDefault[3]&gt;</code></pre>
</div>
<p>We can now tune over this pipeline, and probably running grid search seems a good idea to “touch” every available learner. NB: We have now written down in (much more complicated code) what we did before with <code>benchmark</code>.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
glrn = GraphLearner$new(pipe, id = &quot;g&quot;) # connect pipe to mlr3
ps = ParamSet$new(list(
  ParamFct$new(&quot;branch.selection&quot;, levels = c(&quot;rf&quot;, &quot;xgb&quot;))
))
instance = TuningInstanceSingleCrit$new(
  task = task,
  learner = glrn,
  resampling = cv1,
  measure = msr(&quot;classif.ce&quot;),
  search_space = ps,
  terminator = trm(&quot;none&quot;)
)
tuner = tnr(&quot;grid_search&quot;)
tuner$optimize(instance)</code></pre>
<pre><code>
INFO  [04:44:49.720] Starting to optimize 1 parameter(s) with &#39;&lt;OptimizerGridSearch&gt;&#39; and &#39;&lt;TerminatorNone&gt;&#39; 
INFO  [04:44:49.726] Evaluating 1 configuration(s) 
INFO  [04:44:50.885] Result of batch 1: 
INFO  [04:44:50.887]  branch.selection classif.ce      resample_result 
INFO  [04:44:50.887]               xgb  0.2932692 &lt;ResampleResult[18]&gt; 
INFO  [04:44:50.890] Evaluating 1 configuration(s) 
INFO  [04:44:52.144] Result of batch 2: 
INFO  [04:44:52.147]  branch.selection classif.ce      resample_result 
INFO  [04:44:52.147]                rf  0.2067308 &lt;ResampleResult[18]&gt; 
INFO  [04:44:52.270] Finished optimizing after 2 evaluation(s) 
INFO  [04:44:52.272] Result: 
INFO  [04:44:52.274]  branch.selection learner_param_vals  x_domain classif.ce 
INFO  [04:44:52.274]                rf          &lt;list[3]&gt; &lt;list[1]&gt;  0.2067308 </code></pre>
<pre><code>
   branch.selection learner_param_vals  x_domain classif.ce
1:               rf          &lt;list[3]&gt; &lt;list[1]&gt;  0.2067308</code></pre>
<pre class="r"><code>
instance$archive$data(&quot;x_domain&quot;)</code></pre>
<pre><code>
   branch.selection classif.ce      resample_result           timestamp
1:              xgb  0.2932692 &lt;ResampleResult[18]&gt; 2020-08-03 04:44:50
2:               rf  0.2067308 &lt;ResampleResult[18]&gt; 2020-08-03 04:44:52
   batch_nr x_domain_branch.selection
1:        1                       xgb
2:        2                        rf</code></pre>
<pre class="r"><code>
instance$result</code></pre>
<pre><code>
   branch.selection learner_param_vals  x_domain classif.ce
1:               rf          &lt;list[3]&gt; &lt;list[1]&gt;  0.2067308</code></pre>
</div>
<p>But: Via this approach we can now get unbiased performance results via nested resampling and using the <a href="https://mlr3tuning.mlr-org.com/reference/AutoTuner.html"><code>AutoTuner</code></a> (which would make much more sense if we would select from 100 models and not 2).</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
at = AutoTuner$new(
  learner = glrn,
  resampling = cv1,
  measure = msr(&quot;classif.ce&quot;),
  search_space = ps,
  terminator = trm(&quot;none&quot;),
  tuner = tuner
)
rr = resample(task, at, cv2, store_models = TRUE)</code></pre>
<pre><code>
INFO  [04:44:53.134] Starting to optimize 1 parameter(s) with &#39;&lt;OptimizerGridSearch&gt;&#39; and &#39;&lt;TerminatorNone&gt;&#39; 
INFO  [04:44:53.144] Evaluating 1 configuration(s) 
INFO  [04:44:54.350] Result of batch 1: 
INFO  [04:44:54.353]  branch.selection classif.ce      resample_result 
INFO  [04:44:54.353]               xgb  0.3253012 &lt;ResampleResult[18]&gt; 
INFO  [04:44:54.356] Evaluating 1 configuration(s) 
INFO  [04:44:55.706] Result of batch 2: 
INFO  [04:44:55.708]  branch.selection classif.ce      resample_result 
INFO  [04:44:55.708]                rf   0.253012 &lt;ResampleResult[18]&gt; 
INFO  [04:44:55.814] Finished optimizing after 2 evaluation(s) 
INFO  [04:44:55.816] Result: 
INFO  [04:44:55.818]  branch.selection learner_param_vals  x_domain classif.ce 
INFO  [04:44:55.818]                rf          &lt;list[3]&gt; &lt;list[1]&gt;   0.253012 
INFO  [04:44:57.377] Starting to optimize 1 parameter(s) with &#39;&lt;OptimizerGridSearch&gt;&#39; and &#39;&lt;TerminatorNone&gt;&#39; 
INFO  [04:44:57.381] Evaluating 1 configuration(s) 
INFO  [04:44:58.680] Result of batch 1: 
INFO  [04:44:58.682]  branch.selection classif.ce      resample_result 
INFO  [04:44:58.682]                rf  0.1686747 &lt;ResampleResult[18]&gt; 
INFO  [04:44:58.685] Evaluating 1 configuration(s) 
INFO  [04:44:59.957] Result of batch 2: 
INFO  [04:44:59.959]  branch.selection classif.ce      resample_result 
INFO  [04:44:59.959]               xgb  0.3614458 &lt;ResampleResult[18]&gt; 
INFO  [04:45:00.067] Finished optimizing after 2 evaluation(s) 
INFO  [04:45:00.069] Result: 
INFO  [04:45:00.071]  branch.selection learner_param_vals  x_domain classif.ce 
INFO  [04:45:00.071]                rf          &lt;list[3]&gt; &lt;list[1]&gt;  0.1686747 
INFO  [04:45:01.679] Starting to optimize 1 parameter(s) with &#39;&lt;OptimizerGridSearch&gt;&#39; and &#39;&lt;TerminatorNone&gt;&#39; 
INFO  [04:45:01.684] Evaluating 1 configuration(s) 
INFO  [04:45:03.041] Result of batch 1: 
INFO  [04:45:03.044]  branch.selection classif.ce      resample_result 
INFO  [04:45:03.044]                rf  0.2349398 &lt;ResampleResult[18]&gt; 
INFO  [04:45:03.047] Evaluating 1 configuration(s) 
INFO  [04:45:04.315] Result of batch 2: 
INFO  [04:45:04.317]  branch.selection classif.ce      resample_result 
INFO  [04:45:04.317]               xgb  0.3192771 &lt;ResampleResult[18]&gt; 
INFO  [04:45:04.467] Finished optimizing after 2 evaluation(s) 
INFO  [04:45:04.469] Result: 
INFO  [04:45:04.471]  branch.selection learner_param_vals  x_domain classif.ce 
INFO  [04:45:04.471]                rf          &lt;list[3]&gt; &lt;list[1]&gt;  0.2349398 
INFO  [04:45:06.049] Starting to optimize 1 parameter(s) with &#39;&lt;OptimizerGridSearch&gt;&#39; and &#39;&lt;TerminatorNone&gt;&#39; 
INFO  [04:45:06.053] Evaluating 1 configuration(s) 
INFO  [04:45:07.431] Result of batch 1: 
INFO  [04:45:07.434]  branch.selection classif.ce      resample_result 
INFO  [04:45:07.434]               xgb  0.3057229 &lt;ResampleResult[18]&gt; 
INFO  [04:45:07.436] Evaluating 1 configuration(s) 
INFO  [04:45:08.869] Result of batch 2: 
INFO  [04:45:08.872]  branch.selection classif.ce      resample_result 
INFO  [04:45:08.872]                rf  0.2274814 &lt;ResampleResult[18]&gt; 
INFO  [04:45:08.977] Finished optimizing after 2 evaluation(s) 
INFO  [04:45:08.979] Result: 
INFO  [04:45:08.981]  branch.selection learner_param_vals  x_domain classif.ce 
INFO  [04:45:08.981]                rf          &lt;list[3]&gt; &lt;list[1]&gt;  0.2274814 
INFO  [04:45:10.661] Starting to optimize 1 parameter(s) with &#39;&lt;OptimizerGridSearch&gt;&#39; and &#39;&lt;TerminatorNone&gt;&#39; 
INFO  [04:45:10.667] Evaluating 1 configuration(s) 
INFO  [04:45:11.976] Result of batch 1: 
INFO  [04:45:11.979]  branch.selection classif.ce      resample_result 
INFO  [04:45:11.979]               xgb  0.2576736 &lt;ResampleResult[18]&gt; 
INFO  [04:45:11.981] Evaluating 1 configuration(s) 
INFO  [04:45:13.404] Result of batch 2: 
INFO  [04:45:13.407]  branch.selection classif.ce      resample_result 
INFO  [04:45:13.407]                rf  0.2573867 &lt;ResampleResult[18]&gt; 
INFO  [04:45:13.549] Finished optimizing after 2 evaluation(s) 
INFO  [04:45:13.551] Result: 
INFO  [04:45:13.554]  branch.selection learner_param_vals  x_domain classif.ce 
INFO  [04:45:13.554]                rf          &lt;list[3]&gt; &lt;list[1]&gt;  0.2573867 </code></pre>
<pre class="r"><code>
# access 1st inner tuning result
ll = rr$data$learner[[1]]
ll$tuning_result</code></pre>
<pre><code>
   branch.selection learner_param_vals  x_domain classif.ce
1:               rf          &lt;list[3]&gt; &lt;list[1]&gt;   0.253012</code></pre>
<pre class="r"><code>
ll$archive$data(&quot;x_domain&quot;)</code></pre>
<pre><code>
   branch.selection classif.ce      resample_result           timestamp
1:              xgb  0.3253012 &lt;ResampleResult[18]&gt; 2020-08-03 04:44:54
2:               rf  0.2530120 &lt;ResampleResult[18]&gt; 2020-08-03 04:44:55
   batch_nr x_domain_branch.selection
1:        1                       xgb
2:        2                        rf</code></pre>
</div>
<h2 id="model-selection-and-tuning-with-pipelines">Model-Selection and Tuning with Pipelines</h2>
<p>Now let’s select from our given set of models and tune their hyperparameters. One way to do this is to define a search space for each individual learner, wrap them all with the <code>AutoTuner</code>, then call <a href="https://mlr3.mlr-org.com/reference/benchmark.html"><code>benchmark()</code></a> on them. As this is pretty standard, we will skip this here, and show an even neater option, where you can tune over models and hyperparameters in one go. If you have quite a large space of potential learners and combine this with an efficient tuning algorithm, this can save quite some time in tuning as you can learn during optimization which options work best and focus on them. NB: Many AutoML systems work in a very similar way.</p>
<h3 id="define-the-search-space">Define the Search Space</h3>
<p>Remember, that the pipeline contains a joint set of all contained hyperparameters. Prefixed with the respective PipeOp ID, to make names unique.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
as.data.table(pipe$param_set)[,1:4]</code></pre>
<pre><code>
                                 id    class lower upper
 1:                branch.selection ParamFct    NA    NA
 2:                     xgb.booster ParamFct    NA    NA
 3:                   xgb.watchlist ParamUty    NA    NA
 4:                         xgb.eta ParamDbl     0     1
 5:                       xgb.gamma ParamDbl     0   Inf
 6:                   xgb.max_depth ParamInt     0   Inf
 7:            xgb.min_child_weight ParamDbl     0   Inf
 8:                   xgb.subsample ParamDbl     0     1
 9:            xgb.colsample_bytree ParamDbl     0     1
10:           xgb.colsample_bylevel ParamDbl     0     1
11:            xgb.colsample_bynode ParamDbl     0     1
12:           xgb.num_parallel_tree ParamInt     1   Inf
13:                      xgb.lambda ParamDbl     0   Inf
14:                 xgb.lambda_bias ParamDbl     0   Inf
15:                       xgb.alpha ParamDbl     0   Inf
16:                   xgb.objective ParamUty    NA    NA
17:                 xgb.eval_metric ParamUty    NA    NA
18:                  xgb.base_score ParamDbl  -Inf   Inf
19:              xgb.max_delta_step ParamDbl     0   Inf
20:                     xgb.missing ParamDbl  -Inf   Inf
21:        xgb.monotone_constraints ParamInt    -1     1
22:      xgb.tweedie_variance_power ParamDbl     1     2
23:                     xgb.nthread ParamInt     1   Inf
24:                     xgb.nrounds ParamInt     1   Inf
25:                       xgb.feval ParamUty    NA    NA
26:                     xgb.verbose ParamInt     0     2
27:               xgb.print_every_n ParamInt     1   Inf
28:       xgb.early_stopping_rounds ParamInt     1   Inf
29:                    xgb.maximize ParamLgl    NA    NA
30:                 xgb.sample_type ParamFct    NA    NA
31:              xgb.normalize_type ParamFct    NA    NA
32:                   xgb.rate_drop ParamDbl     0     1
33:                   xgb.skip_drop ParamDbl     0     1
34:                    xgb.one_drop ParamLgl    NA    NA
35:                 xgb.tree_method ParamFct    NA    NA
36:                 xgb.grow_policy ParamFct    NA    NA
37:                  xgb.max_leaves ParamInt     0   Inf
38:                     xgb.max_bin ParamInt     2   Inf
39:                   xgb.callbacks ParamUty    NA    NA
40:                  xgb.sketch_eps ParamDbl     0     1
41:            xgb.scale_pos_weight ParamDbl  -Inf   Inf
42:                     xgb.updater ParamUty    NA    NA
43:                xgb.refresh_leaf ParamLgl    NA    NA
44:            xgb.feature_selector ParamFct    NA    NA
45:                       xgb.top_k ParamInt     0   Inf
46:                   xgb.predictor ParamFct    NA    NA
47:                 xgb.save_period ParamInt     0   Inf
48:                   xgb.save_name ParamUty    NA    NA
49:                   xgb.xgb_model ParamUty    NA    NA
50:     xgb.interaction_constraints ParamUty    NA    NA
51:                xgb.outputmargin ParamLgl    NA    NA
52:                  xgb.ntreelimit ParamInt     1   Inf
53:                    xgb.predleaf ParamLgl    NA    NA
54:                 xgb.predcontrib ParamLgl    NA    NA
55:               xgb.approxcontrib ParamLgl    NA    NA
56:             xgb.predinteraction ParamLgl    NA    NA
57:                     xgb.reshape ParamLgl    NA    NA
58:                    xgb.training ParamLgl    NA    NA
59:                    rf.num.trees ParamInt     1   Inf
60:                         rf.mtry ParamInt     1   Inf
61:                   rf.importance ParamFct    NA    NA
62:                 rf.write.forest ParamLgl    NA    NA
63:                rf.min.node.size ParamInt     1   Inf
64:                      rf.replace ParamLgl    NA    NA
65:              rf.sample.fraction ParamDbl     0     1
66:                rf.class.weights ParamDbl  -Inf   Inf
67:                    rf.splitrule ParamFct    NA    NA
68:            rf.num.random.splits ParamInt     1   Inf
69:         rf.split.select.weights ParamDbl     0     1
70:       rf.always.split.variables ParamUty    NA    NA
71:    rf.respect.unordered.factors ParamFct    NA    NA
72: rf.scale.permutation.importance ParamLgl    NA    NA
73:                   rf.keep.inbag ParamLgl    NA    NA
74:                      rf.holdout ParamLgl    NA    NA
75:                  rf.num.threads ParamInt     1   Inf
76:                  rf.save.memory ParamLgl    NA    NA
77:                      rf.verbose ParamLgl    NA    NA
78:                    rf.oob.error ParamLgl    NA    NA
79:                    rf.max.depth ParamInt  -Inf   Inf
80:                        rf.alpha ParamDbl  -Inf   Inf
81:                     rf.min.prop ParamDbl  -Inf   Inf
82:        rf.regularization.factor ParamUty    NA    NA
83:      rf.regularization.usedepth ParamLgl    NA    NA
84:                         rf.seed ParamInt  -Inf   Inf
85:                      rf.minprop ParamDbl  -Inf   Inf
86:                  rf.predict.all ParamLgl    NA    NA
87:                    rf.se.method ParamFct    NA    NA
                                 id    class lower upper</code></pre>
</div>
<p>We decide to tune the <code>mtry</code> parameter of the random forest and the <code>nrounds</code> parameter of xgboost. Additionally, we tune branching parameter that selects our learner.</p>
<p>We also have to reflect the hierarchical order of the parameter sets (admittedly, this is somewhat inconvenient). We can only set the <code>mtry</code> value if the pipe is configured to use the random forest (<code>ranger</code>). The same applies for the xgboost parameter.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
ps = ParamSet$new(list(
  ParamFct$new(&quot;branch.selection&quot;, levels = c(&quot;rf&quot;, &quot;xgb&quot;)),
  # more complicated, but programmtic way for the above:
  # pipe$param_set$params$branch.selection$clone()
  ParamInt$new(&quot;rf.mtry&quot;, lower = 1L, upper = 20L),
  ParamInt$new(&quot;xgb.nrounds&quot;, lower = 1, upper = 500)
))

# FIXME this seems pretty inconvenient
ps$add_dep(&quot;rf.mtry&quot;, &quot;branch.selection&quot;, CondEqual$new(&quot;rf&quot;))
ps$add_dep(&quot;xgb.nrounds&quot;, &quot;branch.selection&quot;, CondEqual$new(&quot;xgb&quot;))</code></pre>
</div>
<h3 id="tune-the-pipeline-with-a-random-search">Tune the Pipeline with a Random Search</h3>
<p>Very similar code as before, we just swap out the search space. And now use random search.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
instance = TuningInstanceSingleCrit$new(
  task = task,
  learner = glrn,
  resampling = cv1,
  measure = msr(&quot;classif.ce&quot;),
  search_space = ps,
  terminator = trm(&quot;evals&quot;, n_evals = 10)
)
tuner = tnr(&quot;random_search&quot;)
tuner$optimize(instance)</code></pre>
<pre><code>
INFO  [04:45:15.618] Starting to optimize 3 parameter(s) with &#39;&lt;OptimizerRandomSearch&gt;&#39; and &#39;&lt;TerminatorEvals&gt;&#39; 
INFO  [04:45:15.664] Evaluating 1 configuration(s) 
INFO  [04:45:17.294] Result of batch 1: 
INFO  [04:45:17.298]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:45:17.298]                rf      13          NA  0.1778846 &lt;ResampleResult[18]&gt; 
INFO  [04:45:17.328] Evaluating 1 configuration(s) 
INFO  [04:45:18.907] Result of batch 2: 
INFO  [04:45:18.910]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:45:18.910]               xgb      NA         371  0.2019231 &lt;ResampleResult[18]&gt; 
INFO  [04:45:18.933] Evaluating 1 configuration(s) 
INFO  [04:45:20.910] Result of batch 3: 
INFO  [04:45:20.912]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:45:20.912]                rf       1          NA  0.1682692 &lt;ResampleResult[18]&gt; 
INFO  [04:45:20.933] Evaluating 1 configuration(s) 
INFO  [04:45:22.286] Result of batch 4: 
INFO  [04:45:22.289]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:45:22.289]               xgb      NA         337  0.2019231 &lt;ResampleResult[18]&gt; 
INFO  [04:45:22.311] Evaluating 1 configuration(s) 
INFO  [04:45:23.675] Result of batch 5: 
INFO  [04:45:23.678]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:45:23.678]               xgb      NA         354  0.2019231 &lt;ResampleResult[18]&gt; 
INFO  [04:45:23.701] Evaluating 1 configuration(s) 
INFO  [04:45:25.024] Result of batch 6: 
INFO  [04:45:25.027]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:45:25.027]               xgb      NA         339  0.2019231 &lt;ResampleResult[18]&gt; 
INFO  [04:45:25.049] Evaluating 1 configuration(s) 
INFO  [04:45:26.399] Result of batch 7: 
INFO  [04:45:26.402]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:45:26.402]                rf      15          NA  0.1826923 &lt;ResampleResult[18]&gt; 
INFO  [04:45:26.425] Evaluating 1 configuration(s) 
INFO  [04:45:27.779] Result of batch 8: 
INFO  [04:45:27.782]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:45:27.782]                rf       9          NA  0.1682692 &lt;ResampleResult[18]&gt; 
INFO  [04:45:27.804] Evaluating 1 configuration(s) 
INFO  [04:45:29.111] Result of batch 9: 
INFO  [04:45:29.114]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:45:29.114]               xgb      NA         294  0.2019231 &lt;ResampleResult[18]&gt; 
INFO  [04:45:29.136] Evaluating 1 configuration(s) 
INFO  [04:45:30.453] Result of batch 10: 
INFO  [04:45:30.456]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:45:30.456]                rf      12          NA  0.1826923 &lt;ResampleResult[18]&gt; 
INFO  [04:45:30.601] Finished optimizing after 10 evaluation(s) 
INFO  [04:45:30.603] Result: 
INFO  [04:45:30.605]  branch.selection rf.mtry xgb.nrounds learner_param_vals  x_domain classif.ce 
INFO  [04:45:30.605]                rf       1          NA          &lt;list[4]&gt; &lt;list[2]&gt;  0.1682692 </code></pre>
<pre><code>
   branch.selection rf.mtry xgb.nrounds learner_param_vals  x_domain classif.ce
1:               rf       1          NA          &lt;list[4]&gt; &lt;list[2]&gt;  0.1682692</code></pre>
<pre class="r"><code>
instance$archive$data(unnest = &quot;x_domain&quot;)</code></pre>
<pre><code>
    branch.selection rf.mtry xgb.nrounds classif.ce      resample_result
 1:               rf      13          NA  0.1778846 &lt;ResampleResult[18]&gt;
 2:              xgb      NA         371  0.2019231 &lt;ResampleResult[18]&gt;
 3:               rf       1          NA  0.1682692 &lt;ResampleResult[18]&gt;
 4:              xgb      NA         337  0.2019231 &lt;ResampleResult[18]&gt;
 5:              xgb      NA         354  0.2019231 &lt;ResampleResult[18]&gt;
 6:              xgb      NA         339  0.2019231 &lt;ResampleResult[18]&gt;
 7:               rf      15          NA  0.1826923 &lt;ResampleResult[18]&gt;
 8:               rf       9          NA  0.1682692 &lt;ResampleResult[18]&gt;
 9:              xgb      NA         294  0.2019231 &lt;ResampleResult[18]&gt;
10:               rf      12          NA  0.1826923 &lt;ResampleResult[18]&gt;
              timestamp batch_nr x_domain_branch.selection x_domain_rf.mtry
 1: 2020-08-03 04:45:17        1                        rf               13
 2: 2020-08-03 04:45:18        2                       xgb               NA
 3: 2020-08-03 04:45:20        3                        rf                1
 4: 2020-08-03 04:45:22        4                       xgb               NA
 5: 2020-08-03 04:45:23        5                       xgb               NA
 6: 2020-08-03 04:45:25        6                       xgb               NA
 7: 2020-08-03 04:45:26        7                        rf               15
 8: 2020-08-03 04:45:27        8                        rf                9
 9: 2020-08-03 04:45:29        9                       xgb               NA
10: 2020-08-03 04:45:30       10                        rf               12
    x_domain_xgb.nrounds
 1:                   NA
 2:                  371
 3:                   NA
 4:                  337
 5:                  354
 6:                  339
 7:                   NA
 8:                   NA
 9:                  294
10:                   NA</code></pre>
<pre class="r"><code>
instance$result</code></pre>
<pre><code>
   branch.selection rf.mtry xgb.nrounds learner_param_vals  x_domain classif.ce
1:               rf       1          NA          &lt;list[4]&gt; &lt;list[2]&gt;  0.1682692</code></pre>
</div>
<p>The following shows a quick way to visualize the tuning results.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
resdf = instance$archive$data(unnest = &quot;x_domain&quot;)
resdf = reshape(resdf,
  varying = c(&quot;xgb.nrounds&quot;,&quot;rf.mtry&quot;),
  v.name = &quot;param_value&quot;,
  timevar = &quot;param&quot;,
  times = c(&quot;xgb.nrounds&quot;,&quot;rf.mtry&quot;),
  direction=&quot;long&quot;)
library(ggplot2)
g = ggplot(resdf, aes(x = param_value, y = classif.ce))
g = g + geom_point()
g = g + facet_grid(~param, scales = &quot;free&quot;)
g</code></pre>
<p><img src="2020-02-01-tuning-multiplexer_files/figure-html5/unnamed-chunk-11-1.png" width="624" /></p>
</div>
<p>Nested resampling, now really needed:</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
at = AutoTuner$new(
  learner = glrn,
  resampling = cv1,
  measure = msr(&quot;classif.ce&quot;),
  search_space = ps,
  terminator = trm(&quot;evals&quot;, n_evals = 10),
  tuner = tuner
)
rr = resample(task, at, cv2, store_models = TRUE)</code></pre>
<pre><code>
INFO  [04:45:31.637] Starting to optimize 3 parameter(s) with &#39;&lt;OptimizerRandomSearch&gt;&#39; and &#39;&lt;TerminatorEvals&gt;&#39; 
INFO  [04:45:31.679] Evaluating 1 configuration(s) 
INFO  [04:45:32.964] Result of batch 1: 
INFO  [04:45:32.967]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:45:32.967]               xgb      NA         178  0.2048193 &lt;ResampleResult[18]&gt; 
INFO  [04:45:32.989] Evaluating 1 configuration(s) 
INFO  [04:45:34.198] Result of batch 2: 
INFO  [04:45:34.201]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:45:34.201]               xgb      NA         106  0.2048193 &lt;ResampleResult[18]&gt; 
INFO  [04:45:34.222] Evaluating 1 configuration(s) 
INFO  [04:45:35.574] Result of batch 3: 
INFO  [04:45:35.577]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:45:35.577]                rf      17          NA  0.2168675 &lt;ResampleResult[18]&gt; 
INFO  [04:45:35.598] Evaluating 1 configuration(s) 
INFO  [04:45:37.019] Result of batch 4: 
INFO  [04:45:37.022]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:45:37.022]               xgb      NA         428  0.2048193 &lt;ResampleResult[18]&gt; 
INFO  [04:45:37.043] Evaluating 1 configuration(s) 
INFO  [04:45:38.383] Result of batch 5: 
INFO  [04:45:38.385]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:45:38.385]                rf      11          NA  0.2048193 &lt;ResampleResult[18]&gt; 
INFO  [04:45:38.409] Evaluating 1 configuration(s) 
INFO  [04:45:39.662] Result of batch 6: 
INFO  [04:45:39.665]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:45:39.665]               xgb      NA         193  0.2048193 &lt;ResampleResult[18]&gt; 
INFO  [04:45:39.686] Evaluating 1 configuration(s) 
INFO  [04:45:41.023] Result of batch 7: 
INFO  [04:45:41.025]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:45:41.025]                rf      10          NA  0.2228916 &lt;ResampleResult[18]&gt; 
INFO  [04:45:41.046] Evaluating 1 configuration(s) 
INFO  [04:45:42.280] Result of batch 8: 
INFO  [04:45:42.283]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:45:42.283]               xgb      NA         137  0.2048193 &lt;ResampleResult[18]&gt; 
INFO  [04:45:42.305] Evaluating 1 configuration(s) 
INFO  [04:45:43.646] Result of batch 9: 
INFO  [04:45:43.649]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:45:43.649]                rf       8          NA  0.2228916 &lt;ResampleResult[18]&gt; 
INFO  [04:45:43.671] Evaluating 1 configuration(s) 
INFO  [04:45:45.054] Result of batch 10: 
INFO  [04:45:45.057]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:45:45.057]               xgb      NA         332  0.2048193 &lt;ResampleResult[18]&gt; 
INFO  [04:45:45.194] Finished optimizing after 10 evaluation(s) 
INFO  [04:45:45.196] Result: 
INFO  [04:45:45.198]  branch.selection rf.mtry xgb.nrounds learner_param_vals  x_domain classif.ce 
INFO  [04:45:45.198]               xgb      NA         178          &lt;list[3]&gt; &lt;list[2]&gt;  0.2048193 
INFO  [04:45:46.686] Starting to optimize 3 parameter(s) with &#39;&lt;OptimizerRandomSearch&gt;&#39; and &#39;&lt;TerminatorEvals&gt;&#39; 
INFO  [04:45:46.727] Evaluating 1 configuration(s) 
INFO  [04:45:48.145] Result of batch 1: 
INFO  [04:45:48.147]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:45:48.147]                rf      17          NA  0.2590361 &lt;ResampleResult[18]&gt; 
INFO  [04:45:48.169] Evaluating 1 configuration(s) 
INFO  [04:45:49.457] Result of batch 2: 
INFO  [04:45:49.460]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:45:49.460]               xgb      NA         190  0.2650602 &lt;ResampleResult[18]&gt; 
INFO  [04:45:49.481] Evaluating 1 configuration(s) 
INFO  [04:45:50.701] Result of batch 3: 
INFO  [04:45:50.704]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:45:50.704]               xgb      NA          75  0.2650602 &lt;ResampleResult[18]&gt; 
INFO  [04:45:50.727] Evaluating 1 configuration(s) 
INFO  [04:45:52.060] Result of batch 4: 
INFO  [04:45:52.063]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:45:52.063]               xgb      NA         238  0.2650602 &lt;ResampleResult[18]&gt; 
INFO  [04:45:52.085] Evaluating 1 configuration(s) 
INFO  [04:45:53.414] Result of batch 5: 
INFO  [04:45:53.416]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:45:53.416]                rf       7          NA  0.2349398 &lt;ResampleResult[18]&gt; 
INFO  [04:45:53.438] Evaluating 1 configuration(s) 
INFO  [04:45:54.722] Result of batch 6: 
INFO  [04:45:54.724]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:45:54.724]               xgb      NA          68  0.2831325 &lt;ResampleResult[18]&gt; 
INFO  [04:45:54.746] Evaluating 1 configuration(s) 
INFO  [04:45:55.958] Result of batch 7: 
INFO  [04:45:55.961]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:45:55.961]               xgb      NA          89  0.2650602 &lt;ResampleResult[18]&gt; 
INFO  [04:45:55.984] Evaluating 1 configuration(s) 
INFO  [04:45:57.427] Result of batch 8: 
INFO  [04:45:57.429]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:45:57.429]                rf       7          NA  0.2168675 &lt;ResampleResult[18]&gt; 
INFO  [04:45:57.451] Evaluating 1 configuration(s) 
INFO  [04:45:58.805] Result of batch 9: 
INFO  [04:45:58.808]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:45:58.808]                rf       1          NA  0.2650602 &lt;ResampleResult[18]&gt; 
INFO  [04:45:58.830] Evaluating 1 configuration(s) 
INFO  [04:46:00.265] Result of batch 10: 
INFO  [04:46:00.268]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:46:00.268]               xgb      NA         367  0.2650602 &lt;ResampleResult[18]&gt; 
INFO  [04:46:00.403] Finished optimizing after 10 evaluation(s) 
INFO  [04:46:00.404] Result: 
INFO  [04:46:00.406]  branch.selection rf.mtry xgb.nrounds learner_param_vals  x_domain classif.ce 
INFO  [04:46:00.406]                rf       7          NA          &lt;list[4]&gt; &lt;list[2]&gt;  0.2168675 
INFO  [04:46:02.019] Starting to optimize 3 parameter(s) with &#39;&lt;OptimizerRandomSearch&gt;&#39; and &#39;&lt;TerminatorEvals&gt;&#39; 
INFO  [04:46:02.061] Evaluating 1 configuration(s) 
INFO  [04:46:03.454] Result of batch 1: 
INFO  [04:46:03.457]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:46:03.457]                rf       5          NA  0.2771084 &lt;ResampleResult[18]&gt; 
INFO  [04:46:03.478] Evaluating 1 configuration(s) 
INFO  [04:46:04.809] Result of batch 2: 
INFO  [04:46:04.811]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:46:04.811]               xgb      NA         226  0.3192771 &lt;ResampleResult[18]&gt; 
INFO  [04:46:04.833] Evaluating 1 configuration(s) 
INFO  [04:46:06.186] Result of batch 3: 
INFO  [04:46:06.188]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:46:06.188]               xgb      NA         233  0.3192771 &lt;ResampleResult[18]&gt; 
INFO  [04:46:06.210] Evaluating 1 configuration(s) 
INFO  [04:46:07.622] Result of batch 4: 
INFO  [04:46:07.625]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:46:07.625]                rf       2          NA  0.2771084 &lt;ResampleResult[18]&gt; 
INFO  [04:46:07.654] Evaluating 1 configuration(s) 
INFO  [04:46:09.066] Result of batch 5: 
INFO  [04:46:09.069]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:46:09.069]               xgb      NA         312  0.3192771 &lt;ResampleResult[18]&gt; 
INFO  [04:46:09.091] Evaluating 1 configuration(s) 
INFO  [04:46:10.629] Result of batch 6: 
INFO  [04:46:10.633]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:46:10.633]               xgb      NA         481  0.3192771 &lt;ResampleResult[18]&gt; 
INFO  [04:46:10.659] Evaluating 1 configuration(s) 
INFO  [04:46:12.120] Result of batch 7: 
INFO  [04:46:12.123]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:46:12.123]                rf      18          NA  0.2891566 &lt;ResampleResult[18]&gt; 
INFO  [04:46:12.144] Evaluating 1 configuration(s) 
INFO  [04:46:13.583] Result of batch 8: 
INFO  [04:46:13.586]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:46:13.586]                rf       6          NA  0.2650602 &lt;ResampleResult[18]&gt; 
INFO  [04:46:13.608] Evaluating 1 configuration(s) 
INFO  [04:46:15.099] Result of batch 9: 
INFO  [04:46:15.101]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:46:15.101]                rf      18          NA  0.2831325 &lt;ResampleResult[18]&gt; 
INFO  [04:46:15.123] Evaluating 1 configuration(s) 
INFO  [04:46:16.515] Result of batch 10: 
INFO  [04:46:16.518]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:46:16.518]                rf       8          NA  0.2831325 &lt;ResampleResult[18]&gt; 
INFO  [04:46:16.703] Finished optimizing after 10 evaluation(s) 
INFO  [04:46:16.705] Result: 
INFO  [04:46:16.707]  branch.selection rf.mtry xgb.nrounds learner_param_vals  x_domain classif.ce 
INFO  [04:46:16.707]                rf       6          NA          &lt;list[4]&gt; &lt;list[2]&gt;  0.2650602 
INFO  [04:46:18.338] Starting to optimize 3 parameter(s) with &#39;&lt;OptimizerRandomSearch&gt;&#39; and &#39;&lt;TerminatorEvals&gt;&#39; 
INFO  [04:46:18.379] Evaluating 1 configuration(s) 
INFO  [04:46:19.858] Result of batch 1: 
INFO  [04:46:19.860]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:46:19.860]               xgb      NA         249  0.2335055 &lt;ResampleResult[18]&gt; 
INFO  [04:46:19.883] Evaluating 1 configuration(s) 
INFO  [04:46:21.150] Result of batch 2: 
INFO  [04:46:21.153]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:46:21.153]               xgb      NA          53  0.2036001 &lt;ResampleResult[18]&gt; 
INFO  [04:46:21.174] Evaluating 1 configuration(s) 
INFO  [04:46:22.720] Result of batch 3: 
INFO  [04:46:22.723]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:46:22.723]                rf      17          NA  0.2156483 &lt;ResampleResult[18]&gt; 
INFO  [04:46:22.745] Evaluating 1 configuration(s) 
INFO  [04:46:24.066] Result of batch 4: 
INFO  [04:46:24.069]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:46:24.069]               xgb      NA         126  0.2335055 &lt;ResampleResult[18]&gt; 
INFO  [04:46:24.093] Evaluating 1 configuration(s) 
INFO  [04:46:25.667] Result of batch 5: 
INFO  [04:46:25.670]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:46:25.670]               xgb      NA         475  0.2335055 &lt;ResampleResult[18]&gt; 
INFO  [04:46:25.692] Evaluating 1 configuration(s) 
INFO  [04:46:27.170] Result of batch 6: 
INFO  [04:46:27.173]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:46:27.173]               xgb      NA         294  0.2335055 &lt;ResampleResult[18]&gt; 
INFO  [04:46:27.194] Evaluating 1 configuration(s) 
INFO  [04:46:28.673] Result of batch 7: 
INFO  [04:46:28.676]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:46:28.676]                rf      13          NA  0.2096959 &lt;ResampleResult[18]&gt; 
INFO  [04:46:28.697] Evaluating 1 configuration(s) 
INFO  [04:46:30.132] Result of batch 8: 
INFO  [04:46:30.136]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:46:30.136]                rf       3          NA  0.2337206 &lt;ResampleResult[18]&gt; 
INFO  [04:46:30.166] Evaluating 1 configuration(s) 
INFO  [04:46:32.025] Result of batch 9: 
INFO  [04:46:32.028]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:46:32.028]                rf      15          NA  0.2636976 &lt;ResampleResult[18]&gt; 
INFO  [04:46:32.049] Evaluating 1 configuration(s) 
INFO  [04:46:33.154] Result of batch 10: 
INFO  [04:46:33.157]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:46:33.157]               xgb      NA          22  0.2035284 &lt;ResampleResult[18]&gt; 
INFO  [04:46:33.292] Finished optimizing after 10 evaluation(s) 
INFO  [04:46:33.294] Result: 
INFO  [04:46:33.296]  branch.selection rf.mtry xgb.nrounds learner_param_vals  x_domain classif.ce 
INFO  [04:46:33.296]               xgb      NA          22          &lt;list[3]&gt; &lt;list[2]&gt;  0.2035284 
INFO  [04:46:34.600] Starting to optimize 3 parameter(s) with &#39;&lt;OptimizerRandomSearch&gt;&#39; and &#39;&lt;TerminatorEvals&gt;&#39; 
INFO  [04:46:34.641] Evaluating 1 configuration(s) 
INFO  [04:46:35.979] Result of batch 1: 
INFO  [04:46:35.981]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:46:35.981]                rf      19          NA  0.2577453 &lt;ResampleResult[18]&gt; 
INFO  [04:46:36.003] Evaluating 1 configuration(s) 
INFO  [04:46:37.238] Result of batch 2: 
INFO  [04:46:37.241]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:46:37.241]               xgb      NA         228    0.21572 &lt;ResampleResult[18]&gt; 
INFO  [04:46:37.262] Evaluating 1 configuration(s) 
INFO  [04:46:38.540] Result of batch 3: 
INFO  [04:46:38.543]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:46:38.543]               xgb      NA         276    0.21572 &lt;ResampleResult[18]&gt; 
INFO  [04:46:38.565] Evaluating 1 configuration(s) 
INFO  [04:46:39.861] Result of batch 4: 
INFO  [04:46:39.864]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:46:39.864]                rf       1          NA  0.2340075 &lt;ResampleResult[18]&gt; 
INFO  [04:46:39.885] Evaluating 1 configuration(s) 
INFO  [04:46:41.266] Result of batch 5: 
INFO  [04:46:41.269]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:46:41.269]                rf      14          NA  0.2457688 &lt;ResampleResult[18]&gt; 
INFO  [04:46:41.290] Evaluating 1 configuration(s) 
INFO  [04:46:42.506] Result of batch 6: 
INFO  [04:46:42.509]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:46:42.509]               xgb      NA         140    0.21572 &lt;ResampleResult[18]&gt; 
INFO  [04:46:42.530] Evaluating 1 configuration(s) 
INFO  [04:46:43.908] Result of batch 7: 
INFO  [04:46:43.911]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:46:43.911]               xgb      NA         409    0.21572 &lt;ResampleResult[18]&gt; 
INFO  [04:46:43.932] Evaluating 1 configuration(s) 
INFO  [04:46:45.305] Result of batch 8: 
INFO  [04:46:45.308]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:46:45.308]               xgb      NA         420    0.21572 &lt;ResampleResult[18]&gt; 
INFO  [04:46:45.329] Evaluating 1 configuration(s) 
INFO  [04:46:46.683] Result of batch 9: 
INFO  [04:46:46.686]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:46:46.686]                rf      17          NA  0.2516495 &lt;ResampleResult[18]&gt; 
INFO  [04:46:46.708] Evaluating 1 configuration(s) 
INFO  [04:46:48.098] Result of batch 10: 
INFO  [04:46:48.100]  branch.selection rf.mtry xgb.nrounds classif.ce      resample_result 
INFO  [04:46:48.100]               xgb      NA         447    0.21572 &lt;ResampleResult[18]&gt; 
INFO  [04:46:48.249] Finished optimizing after 10 evaluation(s) 
INFO  [04:46:48.251] Result: 
INFO  [04:46:48.253]  branch.selection rf.mtry xgb.nrounds learner_param_vals  x_domain classif.ce 
INFO  [04:46:48.253]               xgb      NA         228          &lt;list[3]&gt; &lt;list[2]&gt;    0.21572 </code></pre>
<pre class="r"><code>
# access 1st inner tuning result
ll = rr$data$learner[[1]]
ll$tuning_result</code></pre>
<pre><code>
   branch.selection rf.mtry xgb.nrounds learner_param_vals  x_domain classif.ce
1:              xgb      NA         178          &lt;list[3]&gt; &lt;list[2]&gt;  0.2048193</code></pre>
<pre class="r"><code>
ll$archive$data(unnest = &quot;x_domain&quot;)</code></pre>
<pre><code>
    branch.selection rf.mtry xgb.nrounds classif.ce      resample_result
 1:              xgb      NA         178  0.2048193 &lt;ResampleResult[18]&gt;
 2:              xgb      NA         106  0.2048193 &lt;ResampleResult[18]&gt;
 3:               rf      17          NA  0.2168675 &lt;ResampleResult[18]&gt;
 4:              xgb      NA         428  0.2048193 &lt;ResampleResult[18]&gt;
 5:               rf      11          NA  0.2048193 &lt;ResampleResult[18]&gt;
 6:              xgb      NA         193  0.2048193 &lt;ResampleResult[18]&gt;
 7:               rf      10          NA  0.2228916 &lt;ResampleResult[18]&gt;
 8:              xgb      NA         137  0.2048193 &lt;ResampleResult[18]&gt;
 9:               rf       8          NA  0.2228916 &lt;ResampleResult[18]&gt;
10:              xgb      NA         332  0.2048193 &lt;ResampleResult[18]&gt;
              timestamp batch_nr x_domain_branch.selection x_domain_xgb.nrounds
 1: 2020-08-03 04:45:32        1                       xgb                  178
 2: 2020-08-03 04:45:34        2                       xgb                  106
 3: 2020-08-03 04:45:35        3                        rf                   NA
 4: 2020-08-03 04:45:37        4                       xgb                  428
 5: 2020-08-03 04:45:38        5                        rf                   NA
 6: 2020-08-03 04:45:39        6                       xgb                  193
 7: 2020-08-03 04:45:41        7                        rf                   NA
 8: 2020-08-03 04:45:42        8                       xgb                  137
 9: 2020-08-03 04:45:43        9                        rf                   NA
10: 2020-08-03 04:45:45       10                       xgb                  332
    x_domain_rf.mtry
 1:               NA
 2:               NA
 3:               17
 4:               NA
 5:               11
 6:               NA
 7:               10
 8:               NA
 9:                8
10:               NA</code></pre>
</div>
<!--radix_placeholder_article_footer-->
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>


<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom">
  <h3 id="citation">Citation</h3>
  <p>For attribution, please cite this work as</p>
  <pre class="citation-appendix short">Richter &amp; Bischl (2020, Feb. 1). mlr3gallery: Tuning Over Multiple Learners. Retrieved from https://mlr3gallery.mlr-org.com/posts/2020-02-01-tuning-multiplexer/</pre>
  <p>BibTeX citation</p>
  <pre class="citation-appendix long">@misc{richter2020tuning,
  author = {Richter, Jakob and Bischl, Bernd},
  title = {mlr3gallery: Tuning Over Multiple Learners},
  url = {https://mlr3gallery.mlr-org.com/posts/2020-02-01-tuning-multiplexer/},
  year = {2020}
}</pre>
</div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
