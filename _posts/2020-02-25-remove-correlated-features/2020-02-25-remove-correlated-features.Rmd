---
title: Select uncorrelated features
categories:
  - tuning
  - mlr3pipelines
  - filtering
author:
  - name: Martin Binder
  - name: Florian Pfisterer
date: 02-25-2020
description: |
  The following example describes a situation where we aim to remove correlated features. This in essence means, that we drop features until no features have a correlation higher then a given `cutoff`. This is often useful when we for example want to use linear models.
output:
  distill::distill_article:
    self_contained: false
    css: ../../custom.css
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  R.options = list(width = 80)
)
library(mlr3book)
```

The following example describes a situation where we aim to remove **correlated features**.
This in essence means, that we drop features until no features have a correlation higher then a given `cutoff`.
This is often useful when we for example want to use **linear models**.

## Prerequisites

This tutorial assumes familiarity with the basics of `r mlr_pkg("mlr3pipelines")`.
Consult the [mlr3book](https://mlr3book.mlr-org.com/pipelines.html) if some aspects are not  fully understandable.
Additionally, we compare different cutoff values via tuning using the `r mlr_pkg("mlr3tuning")` package.
Again, the [mlr3book](https://mlr3book.mlr-org.com/paradox.html) has an intro to `r mlr_pkg("mlr3tuning")` and `r mlr_pkg("paradox")`.

The example describes a very involved use-case, where the behavior of `r ref("PipeOpSelect")` is manipulated via a **trafo** on it's `r ref("ParamSet")`

## Getting started

```{r}
library("mlr3")
library("mlr3pipelines")
library("paradox")
library("mlr3tuning")
```

```{r, include = FALSE}
lgr::get_logger("mlr3")$set_threshold("warn")
lgr::get_logger("mlr3tuning")$set_threshold("warn")
```

The basic pipeline looks as follows:
We use `r ref("PipeOpSelect")` to select a set of variables followed by a `r ref("mlr_learners_classif.rpart", "rpart learner")`.

```{r}
pipeline = po("select") %>>% lrn("classif.rpart")
```

Now we get to the magic:

We want to use the function `r ref("caret::findCorrelation")` from the `r cran_pkg("caret")` package in order to select uncorrelated variables.
This function has a `cutoff` parameter, that specifies the maximum correlation allowed between variables.
In order to expose this variable as a `numeric` parameter we can tune over we specify the following `r ref("ParamSet")`:

```{r}
ps = ParamSet$new(list(ParamDbl$new("cutoff", 0, 1)))
```

We define a function `select_cutoff` that takes as input a `r ref("Task")` and returns a list of features we aim to keep.

Now we use a `trafo` to transform the `cutoff` into a set of variables, which is what `r ref("PipeOpSelect")` can work with.
Note that we use `x$cutoff = NULL` in order to remove the temporary parameter we introduced, as `r ref("PipeOpSelect")` does not know what to do with it.

```{r}
ps$trafo = function(x, param_set) {
  cutoff = x$cutoff
  x$select.selector = function(task) {
    fn = task$feature_names
    data = task$data(cols = fn)
    drop = caret::findCorrelation(cor(data), cutoff = cutoff, exact = TRUE, names = TRUE)
    setdiff(fn, drop)
  }
  x$cutoff = NULL
  x
}
```

If you are not sure, you understand the `trafo` concept, consult the [mlr3book](https://mlr3book.mlr-org.com/paradox.html).
It has a section on the `trafo` concept.

To now tune over different values for `cutoff`, we first create a `r ref("TuningInstance")`.

```{r}
inst = TuningInstance$new(
  task = tsk("iris"),
  learner = pipeline,
  resampling = rsmp("cv", folds = 3L),
  measures = msr("classif.ce"),
  param_set = ps,
  terminator = term("none"),
  # don't need the following line for optimization, this is for
  # demonstration that different features were selected
  bm_args = list(store_models = TRUE)
)
```

and run the tuning:

```{r}
tnr("grid_search")$tune(inst)
```

In order to demonstrate that different cutoff values result in different features being selected, we can run the following to inspect the trained models.
Note this inspects only the trained models of the first CV fold of each evaluated model.
The features being excluded depends on the training data seen by the pipeline and may be different in different folds, even at the same cutoff value

```{r}
inst$archive(unnest = "tune_x")[
  order(cutoff),
  list(cutoff, classif.ce,
    featurenames = lapply(resample_result, function(x) {
      x$learners[[1]]$model$classif.rpart$train_task$feature_names
    }
  ))]
```

Voila, we created our own `r ref("PipeOp")`, that uses very advanced knowledge of `r mlr_pkg("mlr3pipelines")` and `r mlr_pkg("paradox")` in only few lines of code.
