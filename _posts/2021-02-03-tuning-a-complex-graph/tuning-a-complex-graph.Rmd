---
title: Tuning a Complex Graph
categories:
  - mlr3tuning
  - tuning
  - optimization
  - mlr3pipelines
  - classification
  - bst data set
author:
  - name: Lennart Schneider
date: 02-03-2021
description: |
  We show how to tune a complex graph for a single task.
output:
  distill::distill_article:
    self_contained: false
    css: ../../custom.css
bibliography: bibliography.bib
params:
  eval_all: FALSE
---

```{r tuning-a-complex-graph-001, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  R.options = list(width = 120)
)
library(mlr3book)
library(kableExtra)
```

```{r tuning-a-complex-graph-002, include=FALSE, eval = params$eval_all}
future::plan("multicore")
```

In this use case we show how to tune a rather complex graph consisting of different preprocessing steps and different learners where each preprocessing step and learner itself has parameters that can be tuned.
You will learn the following:

* Build a `r ref("Graph", "Graph")` that consists of two common preprocessing steps, then switches between two dimensionality reduction techniques followed by a `r ref("Learner", "Learner")` vs. no dimensionality reduction followed by another `r ref("Learner", "Learner")`
* Define the search space for tuning that handles inter-dependencies between pipeline steps and hyperparameters
* Run a `r ref("TunerGridSearch", "grid search")` to find an optimal choice of preprocessing steps and hyperparameters.

Ideally you already had a look at how to tune over [multiple learners](https://mlr3gallery.mlr-org.com/posts/2020-02-01-tuning-multiplexer/).

First, we load the packages we will need:

```{r tuning-a-complex-graph-003}
library(mlr3verse)
library(mlr3learners)
```

We initialize the random number generator with a fixed seed for reproducibility, and decrease the verbosity of the logger to keep the output clearly represented.
The [`lgr`](https://mlr3book.mlr-org.com/logging.html) package is used for logging in all `r mlr_pkg("mlr3")` packages.
The `r mlr_pkg("mlr3")` logger prints the logging messages from the base package, whereas the `r mlr_pkg("bbotk")`  logger is responsible for logging messages from the optimization packages (e.g. `r mlr_pkg("mlr3tuning")` ).

```{r tuning-a-complex-graph-004}
set.seed(7832)
lgr::get_logger("mlr3")$set_threshold("warn")
lgr::get_logger("bbotk")$set_threshold("warn")
```

## Data and Task

We are going to work with some gene expression data included as a supplement in the `r cran_pkg("bst")` package.
The data consists of 2308 gene profiles in 63 training and 20 test samples.
The following data preprocessing steps are done analogously as in `vignette("khan", package = "bst")`:

```{r tuning-a-complex-graph-005}
datafile = system.file("extdata", "supplemental_data", package = "bst")
dat0 = read.delim(datafile, header = TRUE, skip = 1)[, -(1:2)]
dat0 = t(dat0)
dat = data.frame(dat0[!(rownames(dat0) %in%
  c("TEST.9", "TEST.13", "TEST.5", "TEST.3", "TEST.11")), ])
dat$class = as.factor(
  c(substr(rownames(dat)[1:63], start = 1, stop = 2),
    c("NB", "RM", "NB", "EW", "RM", "BL", "EW", "RM", "EW", "EW", "EW", "RM",
      "BL", "RM", "NB", "NB", "NB", "NB", "BL", "EW")
  )
)
```

We then construct our training and test `r ref("Task", "Task")` :

```{r tuning-a-complex-graph-006}
task = as_task_classif(dat, target = "class", id = "SRBCT")
task_train = task$clone(deep = TRUE)
task_train$filter(1:63)
task_test = task$clone(deep = TRUE)
task_test$filter(64:83)
```

## Workflow

Our graph will start with log transforming the features, followed by scaling them.
Then, either a `r ref("PipeOpPCA", "PCA")` or `r ref("PipeOpICA", "ICA")` is applied to extract principal / independent components followed by fitting a `r ref("mlr_learners_classif.lda", "LDA")` or a `r ref("mlr_learners_classif.ranger", "ranger random forest")` is fitted without any preprocessing (the log transformation and scaling should most likely affect the `LDA` more than the `ranger random forest`).
Regarding the `PCA` and `ICA`, both the number of principal / independent components are tuning parameters.
Regarding the `LDA`, we can further choose different methods for estimating the mean and variance and regarding the `ranger`, we want to tune the `mtry` and `num.tree` parameters.
Note that the `PCA-LDA` combination has already been successfully applied in different cancer diagnostic contexts when the feature space is of high dimensionality [@morais2018].

To allow for switching between the `PCA` / `ICA`-`LDA` and `ranger` we can either use branching or proxy pipelines, i.e., `r ref("PipeOpBranch", "PipeOpBranch")` and `r ref("PipeOpUnbranch", "PipeOpUnbranch")` or `r ref("PipeOpProxy", "PipeOpProxy")`.
We will first cover branching in detail and later show how the same can be done using `PipeOpProxy`.

## Baseline

First, we have a look at the baseline `r ref("mlr_measures_classif.acc", "classification accuracy")` of the `LDA` and `ranger` on the training task:

```{r tuning-a-complex-graph-007}
base = benchmark(benchmark_grid(
  task_train,
  learners = list(lrn("classif.lda"), lrn("classif.ranger")),
  resamplings = rsmp("cv", folds = 3)))
base$aggregate(measures = msr("classif.acc"))
```

The out-of-the-box `ranger` appears to already have good performance on the training task.
Regarding the `LDA`, we do get a warning message that some features are colinear.
This strongly suggests to reduce the dimensionality of the feature space.
Let's see if we can get some better performance, at least for the `LDA`.

## Branching

Our graph starts with log transforming the features (we explicitly use base 10 only for better interpretability when inspecting the model later), using `r ref("PipeOpColApply", "PipeOpColApply")`, followed by scaling the features using `r ref("PipeOpScale", "PipeOpScale")`.
Then, the first branch allows for switching between the `PCA` / `ICA`-`LDA` and `ranger`, and within `PCA` / `ICA`-`LDA`, the second branch allows for switching between `PCA` and `ICA`:

```{r tuning-a-complex-graph-008}
graph1 =
  po("colapply", applicator = function(x) log(x, base = 10)) %>>%
  po("scale") %>>%
  # pca / ica followed by lda vs. ranger
  po("branch", id = "branch_learner", options = c("pca_ica_lda", "ranger")) %>>%
  gunion(list(
    po("branch", id = "branch_preproc_lda", options = c("pca", "ica")) %>>%
      gunion(list(
        po("pca"), po("ica")
      )) %>>%
      po("unbranch", id = "unbranch_preproc_lda") %>>%
      lrn("classif.lda"),
    lrn("classif.ranger")
  )) %>>%
  po("unbranch", id = "unbranch_learner")
```

Note that the names of the options within each branch are arbitrary, but ideally they describe what is happening.
Therefore we go with `"pca_ica_lda"` / `"ranger`" and `"pca"` / `"ica"`.
Finally, we also could have used the `branch` `r ref("ppl", "ppl")` to make branching easier (we will come back to this in the [Proxy](#Proxy) section).
The graph looks like the following:

```{r tuning-a-complex-graph-009, layout="l-body-outset", fig.width=6}
graph1$plot()
```
We can inspect the parameters of the `r ref("ParamSet", "ParamSet")` of the graph to see which parameters can be set:

```{r tuning-a-complex-graph-010}
graph1$param_set$ids()
```

The `id`'s are prefixed by the respective `r ref("PipeOp", "PipeOp")` they belong to, e.g., `pca.rank.` refers to the `rank.` parameter of `r ref("PipeOpPCA", "PipeOpPCA")`.

## Search Space

Our graph either fits a `LDA` after applying `PCA` or `ICA`, or alternatively a `ranger` with no preprocessing.
These two **options** each define selection parameters that we can tune.
Moreover, within the respective `PipeOp`'s we want to tune the following parameters:
`pca.rank.`, `ica.n.comp`, `classif.lda.method`, `classif.ranger.mtry`, and `classif.ranger.num.trees`.
The first two parameters are integers that in-principal could range from 1 to the number of features.
However, for `ICA`, the upper bound must not exceed the number of observations and as we will later use `3-fold` `r ref("mlr_resamplings_cv", "cross-validation")` as the resampling method for the tuning, we just set the upper bound to 30 (and do the same for `PCA`).
Regarding the `classif.lda.method` we will only be interested in `"moment"` estimation vs. minimum volume ellipsoid covariance estimation (`"mve"`).
Moreover, we set the lower bound of `classif.ranger.mtry` to 200 (which is around the number of features divided by 10) and the upper bound to 1000.

```{r tuning-a-complex-graph-011}
tune_ps1 = ps(
  branch_learner.selection = p_fct(levels = c("pca_ica_lda", "ranger")),
  branch_preproc_lda.selection = p_fct(levels = c("pca", "ica"), depends = branch_learner.selection == "pca_ica_lda"),
  pca.rank. = p_int(lower = 1, upper = 30, depends = branch_preproc_lda.selection == "pca"),
  ica.n.comp = p_int(lower = 1, upper = 30, depends = branch_preproc_lda.selection == "ica"),
  classif.lda.method = p_fct(levels = c("moment", "mve"), depends = branch_preproc_lda.selection == "ica"),
  classif.ranger.mtry = p_int(lower = 200, upper = 1000, depends = branch_learner.selection == "ranger"),
  classif.ranger.num.trees = p_int(lower = 500, upper = 2000, depends = branch_learner.selection == "ranger"))
```

The parameter `branch_learner.selection` defines whether we go down the left (`PCA` / `ICA` followed by `LDA`) or the right branch (`ranger`).
The parameter `branch_preproc_lda.selection` defines whether a `PCA` or `ICA` will be applied prior to the `LDA`.
The other parameters directly belong to the `ParamSet` of the `PCA` / `ICA` / `LDA` / `ranger`.
Note that it only makes sense to switch between `PCA` / `ICA` if the `"pca_ica_lda"` branch was selected beforehand.
We have to specify this via the `depends` parameter.

Finally, we also could have proceeded to tune the numeric parameters on a log scale.
I.e., looking at `pca.rank.` the performance difference between rank 1 and 2 is probably much larger than between rank 29 and rank 30.
The [mlr3tuning Tutorial](https://mlr3gallery.mlr-org.com/posts/2020-03-11-mlr3tuning-tutorial-german-credit/#random-search-and-transformation) covers such transformations.

## Tuning

We can now tune the parameters of our graph as defined in the search space with respect to a measure.
We will use the `r ref("mlr_measures_classif.acc", "classification accuracy")`.
As a resampling method we use `r ref("mlr_resamplings_cv", "3-fold cross-validation")`.
We will use the `r ref("TerminatorNone", "TerminatorNone")` (i.e., no early termination) for terminating the tuning because we will apply a `r ref("TunerGridSearch", "grid search")` (we use a `grid search` because it gives nicely plottable and understandable results but if there were much more parameters, `r ref("TunerRandomSearch", "random search")` or more intelligent optimization methods would be preferred to a `grid search`:

```{r tuning-a-complex-graph-012}
tune1 = TuningInstanceSingleCrit$new(
  task_train,
  learner = graph1,
  resampling = rsmp("cv", folds = 3),
  measure = msr("classif.acc"),
  search_space = tune_ps1,
  terminator = trm("none")
)
```

We then perform a `grid search` using a resolution of 4 for the numeric parameters.
The grid being used will look like the following (note that the dependencies we specified above are handled automatically):

```{r tuning-a-complex-graph-013, eval = FALSE}
generate_design_grid(tune_ps1, resolution = 4)
```

```{r tuning-a-complex-graph-014, echo = FALSE}
generate_design_grid(tune_ps1, resolution = 4)$data %>%
  kable(format = "html") %>%
  kable_styling() %>%
  kableExtra::scroll_box(height = "400px")
```

We trigger the tuning.

```{r tuning-a-complex-graph-015, eval = params$eval_all}
tuner_gs = tnr("grid_search", resolution = 4, batch_size = 10)
tuner_gs$optimize(tune1)
```

```{r tuning-a-complex-graph-016, echo = FALSE, eval = params$eval_all}
saveRDS(tune1, "data/tune1.rda")
```

```{r tuning-a-complex-graph-017, echo = FALSE}
tune1 = readRDS("data/tune1.rda")
```

Now, we can inspect the results ordered by the `classification accuracy`:

```{r tuning-a-complex-graph-018, eval = FALSE}
as.data.table(tune1$archive, unnest = NULL, exclude_columns = c("x_domain", "uhash", "resample_result"))[order(classif.acc), ]
```

```{r tuning-a-complex-graph-019, echo = FALSE, layout="l-page"}
as.data.table(tune1$archive, unnest = NULL, exclude_columns = c("x_domain", "uhash", "resample_result"))[order(classif.acc), ] %>%
  kable(format = "html") %>%
  kable_styling() %>%
  kableExtra::scroll_box(width = "100%", height = "400px")
```

We achieve very good accuracy using `ranger`, more or less regardless how `mtry` and `num.trees` are set. However, the `LDA` also shows very good accuracy when combined with `PCA` or `ICA` retaining 30 components.

For now, we decide to use `ranger` with `mtry` set to 200 and `num.trees` set to 1000.

Setting these parameters manually in our graph, then training on the training task and predicting on the test task yields an accuracy of:

```{r tuning-a-complex-graph-020}
graph1$param_set$values$branch_learner.selection = "ranger"
graph1$param_set$values$classif.ranger.mtry = 200
graph1$param_set$values$classif.ranger.num.trees = 1000
graph1$train(task_train)
graph1$predict(task_test)[[1L]]$score(msr("classif.acc"))
```

Note that we also could have wrapped our graph in a `r ref("GraphLearner", "GraphLearner")` and proceeded to use this as a learner in an `r ref("AutoTuner", "AutoTuner")`.

## Proxy

Instead of using branches to split our graph with respect to the learner and preprocessing options, we can also use `r ref("PipeOpProxy", "PipeOpProxy")`.
`PipeOpProxy` accepts a single `content` parameter that can contain any other `PipeOp` or `Graph`.
This is extremely flexible in the sense that we do not have to specify our options during construction.
However, the parameters of the contained `PipeOp` or `Graph` are no longer directly contained in the `ParamSet` of the resulting graph.
Therefore, when tuning the graph, we do have to make use of a `trafo` function.

```{r tuning-a-complex-graph-021}
graph2 =
  po("colapply", applicator = function(x) log(x, base = 10)) %>>%
  po("scale") %>>%
  po("proxy")
```

This graph now looks like the following:

```{r tuning-a-complex-graph-022, graph2}
graph2$plot()
```

At first, this may look like a linear graph. However, as the `content` parameter of `PipeOpProxy` can be tuned and set to contain any other `PipeOp` or `Graph`, this will allow for a similar non-linear graph as when doing branching.

```{r tuning-a-complex-graph-023}
graph2$param_set$ids()
```

We can tune the graph by using the same search space as before. However, here the `trafo` function is of central importance to actually set our options and parameters:

```{r tuning-a-complex-graph-024}
tune_ps2 = tune_ps1$clone(deep = TRUE)
```

The `trafo` function does all the work, i.e., selecting either the `PCA` / `ICA`-`LDA` or `ranger` as the `proxy.content` as well as setting the parameters of the respective preprocessing `PipeOp`s and `Learner`s.

```{r tuning-a-complex-graph-025}
proxy_options = list(
  pca_ica_lda =
    ppl("branch", graphs = list(pca = po("pca"), ica = po("ica"))) %>>%
      lrn("classif.lda"),
  ranger = lrn("classif.ranger")
)
```

Above, we made use of the `branch` `r ref("ppl", "ppl")` allowing us to easily construct a branching graph.
Of course we also could have use another nested `PipeOpProxy` to specify the preprocessing options (`"pca"` vs. `"ica"`) within `proxy_options` if for some reason we do not want to do branching at all.
The `trafo` function below selects one of the `proxy_options` from above and sets the respective parameters for the `PCA`, `ICA`, `LDA` and `ranger`.
Here, the argument `x` is a list which will contain sampled / selected parameters from our `ParamSet` (in our case, `tune_ps2`).
The return value is a list only including the appropriate `proxy.content` parameter.
In each tuning iteration, the `proxy.content` parameter of our graph will be set to this value.

```{r tuning-a-complex-graph-026}
tune_ps2$trafo = function(x, param_set) {
  proxy.content = proxy_options[[x$branch_learner.selection]]
  if (x$branch_learner.selection == "pca_ica_lda") {
    # pca_ica_lda
    proxy.content$param_set$values$branch.selection = x$branch_preproc_lda.selection
    if (x$branch_preproc_lda.selection == "pca") {
      proxy.content$param_set$values$pca.rank. = x$pca.rank.
    } else {
      proxy.content$param_set$values$ica.n.comp = x$ica.n.comp
    }
    proxy.content$param_set$values$classif.lda.method = x$classif.lda.method
  } else {
    # ranger
    proxy.content$param_set$values$mtry = x$classif.ranger.mtry
    proxy.content$param_set$values$num.trees = x$classif.ranger.num.trees
  }
  list(proxy.content = proxy.content)
}
```

I.e., suppose that the following parameters will be selected from our `ParamSet`:

```{r tuning-a-complex-graph-027}
x = list(
  branch_learner.selection = "ranger",
  classif.ranger.mtry = 200,
  classif.ranger.num.trees = 500)
```

The `trafo` function will then return:

```{r tuning-a-complex-graph-028}
tune_ps2$trafo(x)
```

Tuning can be carried out analogously as done above:

```{r tuning-a-complex-graph-029, eval = FALSE}
tune2 = TuningInstanceSingleCrit$new(
  task_train,
  learner = graph2,
  resampling = rsmp("cv", folds = 3),
  measure = msr("classif.acc"),
  search_space = tune_ps2,
  terminator = trm("none")
)
tuner_gs$optimize(tune2)
```

```{r tuning-a-complex-graph-030, eval = FALSE}
as.data.table(tune2$archive)[order(classif.acc), ]
```
