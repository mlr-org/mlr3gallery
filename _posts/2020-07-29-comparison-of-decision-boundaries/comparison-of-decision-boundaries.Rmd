---
title: Comparison of Decision Boundaries of Classification Learners
categories:
  - classification
  - visualization
  - mlr3viz
author:
  - name: Michel Lang
description: |
  This post visuzalizes multiple decision boundaries on artificial data sets using the `mlr3viz` package.
date: 07-29-2020
output:
  distill::distill_article:
    self_contained: false
    css: ../../custom.css
---

```{r setup, include=FALSE}
library("mlr3book")
```


The visualization of decision boundaries help to understand what the pros and cons of individual classification learners are.
This posts demonstrates how to create a comparison plot, including multiple tasks and classification learners.

```{r}
library("mlr3")
```

## Artificial Data Sets

The three artificial data sets are generated by `r ref("TaskGenerator", text = "task generators")` (implemented in `r mlr_pkg("mlr3")`):

```{r}
library("mlr3")

N = 100
tasks = list(
  tgen("xor")$generate(N),
  tgen("moons")$generate(N),
  tgen("circle")$generate(N)
)
```


### XOR

Points are distributed on a 2-dimensional cube with corners $(\pm 1, \pm 1)$.
Class is `"red"` if $x$ and $y$ have the same sign, and `"black"` otherwise.

```{r, echo = TRUE}
plot(tgen("xor"))
```


### Circle

Two circles with same center but different radii.
Points in the smaller circle are `"black"`, points only in the larger circle are `"red"`.

```{r, echo = TRUE}
plot(tgen("circle"))
```

### Moons
Two interleaving half circles ("moons").

```{r, echo = TRUE}
plot(tgen("moons"))
```



## Learners

We consider the following learners:

```{r, echo = TRUE}
library("mlr3learners")

learners = list(
  # k-nearest neighbours classifier
  lrn("classif.kknn", id = "kkn", predict_type = "prob", k = 3),

  # linear svm
  lrn("classif.svm", id = "lin. svm", predict_type = "prob", kernel = "linear"),

  # radial-basis function svm
  lrn("classif.svm", id = "rbf svm", predict_type = "prob", kernel = "radial",
    gamma = 2, cost = 1, type = "C-classification"),

  # naive bayes
  lrn("classif.naive_bayes", predict_type = "prob"),

  # single decision tree
  lrn("classif.rpart", predict_type = "prob", cp = 0, maxdepth = 5),

  # random forest
  lrn("classif.ranger", predict_type = "prob")
)
```
The hyperparameters are chosen in a way that the decision boundaries look "typical" for the respective classifier.
Of course, with different hyperparameters, results may look very different.

## Fitting the Models

To apply each learner on each task, we first build an exhaustive grid design of experiments with `r ref("benchmark_grid()")` and then pass it to `r ref("benchmark()")` to do the actual work.
A simple holdout resampling is used here:

```{r, echo = TRUE}
design = benchmark_grid(
  tasks = tasks,
  learners = learners,
  resamplings = rsmp("holdout")
)

bmr = benchmark(design, store_models = TRUE)
```

## Plotting

To generate the plot, we iterate over the individual `r ref("ResampleResult")` objects stored in the `r ref("BenchmarkResult")`, and in each iteration we plot the learner prediction using the `r mlr_pkg("mlr3viz")` package.
Note that only observations from the test data is plotted as points.

```{r, echo = FALSE, fig.width = 15, fig.height = 9}
library(mlr3viz)
simple_plot = function(rr) {
  autoplot(rr, type = "prediction") +
    ggplot2::ggtitle(rr$learners[[1L]]$id) +
    ggplot2::theme(legend.position = "none") +
    ggplot2::xlab("") + ggplot2::ylab("")
}

plots = lapply(seq_len(bmr$n_resample_results), function(i) {
  simple_plot(bmr$resample_result(i))
})

gridExtra::grid.arrange(grobs = plots, nrow = length(tasks))
```

As you can see, the decision boundaries are very different.
Some are linear, others are parallel to the axis, and yet others are highly non-linear.
The boundaries are partly very smooth with a slow transition of probabilities, others are very abrupt.
All these properties are important during model selection, and should be considered for your problem at hand.
