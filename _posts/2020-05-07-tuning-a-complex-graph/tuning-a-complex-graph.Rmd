---
title: "Tuning a complex graph"
categories:
  - tuning
  - mlr3pipelines
  - classification
author:
  - name: Lennart Schneider
date: 04-18-2020
description: |
  We show how to tune a complex graph for a single task.
output:
  distill::distill_article:
    self_contained: false
    css: ../../custom.css
bibliography: biblio.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  R.options = list(width = 80)
)
library(mlr3book)
```

FIXME: hyperlinks

FIXME: when do we actually say graph vs. pipeline

In this use case we show how to tune a rather complex graph consisting of different preprocessing steps and different learners where each preprocessing step and learner itself has parameters that can be tuned.
You will learn the following:

* Build a pipeline that consists of two common preprocessing steps, then switches between further multiple preprocessing steps and finally switches between multiple learners
* Define the hyperparameter search space
* Run a random search terminated by the number of evaluations

Ideally you already had a look at how to tune over multiple learners. FIXME: URL

First, we load the packages we will need and set some logging thresholds:

```{r}
library(mlr3)
library(mlr3tuning)
library(mlr3pipelines)
library(mlr3learners)
library(paradox)
lgr::get_logger("mlr3")$set_threshold("warn")
lgr::get_logger("mlr3tuning")$set_threshold("warn")
```

## Data and Task

We are going to work with some gene expression data included as a supplement in the `bst` package. The data consists of 2308 gene profiles in 63 training and 20 test samples.
The following data preprocessing steps are done analogously as in `vignette("khan", package = "bst")`:

```{r}
datafile = system.file("extdata", "supplemental_data", package = "bst")
dat0 = read.delim(datafile, header = TRUE, skip = 1)[, -(1:2)]
dat0 = t(dat0)
dat1 = dat0[rownames(dat0) %in% c("TEST.9", "TEST.13","TEST.5", "TEST.3", "TEST.11"), ]
dat2 = dat0[rownames(dat0) %nin% c("TEST.9", "TEST.13","TEST.5", "TEST.3", "TEST.11"), ]
dat = data.frame(rbind(dat2, dat1)[1:83, ])
dat$classes = as.factor(c(substr(rownames(dat)[1:63], start = 1, stop = 2), c("NB", "RM", "NB", "EW", "RM", "BL", "EW", "RM", "EW", "EW", "EW", "RM", "BL", "RM", "NB", "NB", "NB", "NB", "BL", "EW")))
```

We then construct our training and test task:

```{r}
task = TaskClassif$new("SRBCT", backend = dat, target = "classes")
task_train = task$clone(deep = TRUE)
task_train$filter(1:63)
task_test = task$clone(deep = TRUE)
task_test$filter(64:83)
```

## Workflow

Our pipeline will consist of log transforming the features (base 10), followed by scaling the features before either applying a PCA or ICA to extract principal / independent components. Here, both the number of principal / independent components is a tuning parameter. We will then either fit a LDA or random forest as a learner, where we can further choose different methods for estimating the mean and variance for the LDA and tune the `mtry`  and `num.tree` parameters of the random forest. Note that the PCA-LCA combination has already been succesfully applied in different cancer diagnostic contexts [@morais2018] and performing dimensionality reduction before fitting a random forest may also be helpful when dealing with `P greather than N` problems.

To allow for switching between PCA/ICA and LDA/random forest we can either use branching or proxy pipelines within, i.e., `PipeOpBranch` and `PipeOpUnbranch` or `PipeOpProxy`. We will first cover branching in detail and later show how the same can be done using `PipeOpProxy`.

## Baseline

First, we have a look at the baseline `classification accuracy` of the LDA and random forest on the training task:

```{r}
base = benchmark(benchmark_grid(task_train, learners = list(lrn("classif.lda"), lrn("classif.ranger")), resamplings = rsmp("cv", folds = 3)))
base$aggregate(measures = msr("classif.acc"))
```

The out of box random forest appears to already have good performance. Regarding the LDA, we do get a warning message, that some features are collinear. This strongly suggests to reduce the dimensionality of the feature space.

## Branching

Our pipeline starts with log transforming the features (base 10), using `PipeOpColApply`, followed by scaling the features using `PipeOpScale`. Then, the first branch allows for switching between a PCA and ICA, while the second branch allows for switching between a LDA and random forest as learners:

```{r}
pipeline1 = po("colapply", param_vals = list(applicator = function(x) log(x, base = 10))) %>>%
  po("scale") %>>%
  # first branch for preprocessing
  po("branch", id = "branch_preproc", options = c("pca", "ica")) %>>%
  gunion(list(po("pca"), po("ica"))) %>>%
  po("unbranch", id = "unbranch_preproc") %>>%
  # second branch for learners
  po("branch", id = "branch_learner", options = c("classif.lda", "classif.ranger")) %>>%
  gunion(list(lrn("classif.lda"), lrn("classif.ranger"))) %>>%
  po("unbranch", id = "unbranch_learner")
```

Note that the names of the options within each branch are arbitrary, but ideally they describe what is happening, therefore we go with `"pca"`/`"ica"` and `"classif.lda"`/`"classif.ranger"`. The pipeline looks like the following:

```{r}
pipeline1$plot()
```
We can inspect the parameters of the `ParamSet` of the pipeline to see which parameters can be set:

```{r}
pipeline1$param_set$ids()
```

Note that the `id`'s are prefixed by the respective `PipeOp` they belong to, e.g., `pca.rank.` refers to the `rank.` parameter of the `pca` `PipeOP`.

## Search Space

Our pipeline either performs a PCA or ICA during preprocessing and either uses a LDA or random forest as a learner. These two selections each define selection parameters that we can tune. Moreover, within the respective `PipeOp`'s we want to tune the following parameters: `pca.rank.`, `ica.n.comp`, `classif.lda.method`, `classif.ranger.mtry`, and `classif.ranger.num.trees`. The first two parameters are integers that in principal could range from 1 to the number of features. However, for ICA, the upper bound must not exceed the number of rows and as we will later use `3-fold crossvalidation` as the resampling method for the tuning, we just set the upper bound to 30 (and do the same for the PCA). Regarding the `classif.lda.method` we will only be interested in `moment` estimation vs. minimum volume ellipsoid covariance estimation (`mve`). Finally, `classif.ranger.mtry` could in principle again range from 1 to the number of features. However, as we apply dimensionality reduction techniques prior to fitting the random forest, the upper bound of this parameter further depends on the `pca.rank.` and `ica.n.comp` parameter. We will handle this with a transformation function. To set up our search space we define a new `ParamSet`:

```{r}
tune_ps1 = ParamSet$new(list(
  ParamFct$new("branch_preproc.selection", levels = c("pca", "ica")),
  ParamInt$new("pca.rank.", lower = 1, upper = 30),
  ParamInt$new("ica.n.comp", lower = 1, upper = 30),
  ParamFct$new("branch_learner.selection", levels = c("classif.lda", "classif.ranger")),
  ParamFct$new("classif.lda.method", levels = c("moment", "mve")),
  ParamInt$new("classif.ranger.mtry", lower = 1, upper = 50),
  ParamInt$new("classif.ranger.num.trees", lower = 500, upper = 2000))
)
```

The parameters `branch_preproc.selection`, and `branch_learner.selection` define whether a PCA or ICA will be applied and a LDA or random forest will be fit in the respective step.
Moreover, regarding the `pca.rank.` parameter, there is a dependency on that `pca` must have been selected in `branch_preproc.selection` which we have to explicitly specify:

```{r}
tune_ps1$add_dep("pca.rank.", on = "branch_preproc.selection", cond = CondEqual$new("pca"))
```

The same holds for the following parameters analogously:

```{r}
tune_ps1$add_dep("ica.n.comp", on = "branch_preproc.selection", cond = CondEqual$new("ica"))
tune_ps1$add_dep("classif.lda.method", on = "branch_learner.selection", cond = CondEqual$new("classif.lda"))
tune_ps1$add_dep("classif.ranger.mtry", on = "branch_learner.selection", cond = CondEqual$new("classif.ranger"))
tune_ps1$add_dep("classif.ranger.num.trees", on = "branch_learner.selection", cond = CondEqual$new("classif.ranger"))
```

Finally, regarding the dependency of `classif.ranger.mtry` on `pca.rank.` and `ica.n.comp`, we define a transformation function. Here `x` will contain a named list of parameters sampled from the `param_set`. We store the `pca.rank.` or `ica.n.comp` value depending on which preprocessing step was sampled and if `classif.ranger.mtry` exceeds this number, we resample but adjust the upper bound:

```{r}
tune_ps1$trafo = function(x, param_set) {
  ndim = if (x$branch_preproc.selection == "pca") x$pca.rank. else x$ica.n.comp
  if (x$branch_learner.selection == "classif.ranger" && x$classif.ranger.mtry > ndim) {
    x$classif.ranger.mtry = sample(param_set$lower["classif.ranger.mtry"]:ndim, size = 1)
  }
  x
}
```

## Tuning

We can now tune the parameters of our pipeline as defined in the search space with respect to a measure. Here, we will use the `classification accuracy`. As a resampling method we use `3-fold cross-validation`. Due to shortage of time, we terminate the tuning after 50 evaluations (note that this will still take some time, so this may be a good time for a 10 minute coffee/tea break).

```{r}
tune1 = TuningInstance$new(task_train, learner = pipeline1, resampling = rsmp("cv", folds = 3), measures = msr("classif.acc"), param_set = tune_ps1, terminator = term("evals", n_evals = 50))
```

We then perform a `random search`:

```{r}
set.seed(2906)
tnr("random_search")$tune(tune1)
```

Now, we can inspect the results, ordered by the `classification accuracy`:

```{r}
tune1_results = tune1$archive(unnest = "params")
tune1_results[order(classif.acc), ]
```

Here, we achieve the best performance using ICA retaining 17 components and fitting a LDA via moment estimation.

Setting these parameters manually in our pipeline, then training on the training task and predicting on the test task yields a `classification accuracy` of:
```{r}
pipeline1$param_set$values$branch_preproc.selection = "ica"
pipeline1$param_set$values$ica.n.comp = 17
pipeline1$param_set$values$branch_learner.selection = "classif.lda"
pipeline1$param_set$values$classif.lda.method = "moment"
pipeline1$train(task_train)
acc$score(pipeline1$predict(task_test)[[1L]])
```

## Proxy

FIXME:
