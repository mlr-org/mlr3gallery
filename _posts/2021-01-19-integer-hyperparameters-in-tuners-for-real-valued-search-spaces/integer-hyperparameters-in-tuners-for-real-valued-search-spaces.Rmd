---
title: "Integer Hyperparameters in Tuners for Real-valued Search Spaces"
description: |
  How to tune integer hyperparameters with tuners that can only propose real numbers.
author:
  - name: Marc Becker
date: 01-19-2021
output:
  distill::distill_article:
    self_contained: false
    css: ../../custom.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  R.options = list(width = 80)
)

library("mlr3book")
```

## Intro

`r ref("Tuner")` for real-valued search spaces are not able to tune on integer hyperparameters. 
However, it is possible to round the real values proposed by a `r ref("Tuner")` to integers before passing them to the learner in the evaluation. 
We show how to apply a parameter transformation to a `r ref("ParamSet")` and use this set in the tuning process.

We load the `r mlr_pkg("mlr3verse")` package which pulls in the most important packages for this example and we decrease the verbosity of the logger to keep the output clearly represented.
```{r}
library(mlr3verse)

lgr::get_logger("mlr3")$set_threshold("warn")
lgr::get_logger("bbotk")$set_threshold("warn")
```

## Task and Learner

In this example, we use the k-Nearest-Neighbor classification learner.
We want to tune the integer-valued hyperparameter `k` which defines the numbers of neighbors.
```{r}
learner = lrn("classif.kknn")
print(learner$param_set$params$k)
```

We choose the `iris` dataset to demonstrate the tuning.
```{r}
task = tsk("iris")
print(task)
```

# Tuning

We choose generalized simulated annealing as tuning strategy.
The `param_classes` field of `r ref("TunerGenSA")` states that the tuner only supports real-valued (`ParamDbl`) hyperparameter tuning.
```{r}
tuner = tnr("gensa")
print(tuner)
```

To get integer-valued hyperparameter values for `k`, we construct a search space with a transformation function.
The `as.integer()` function converts any real valued number to an integer by removing the decimal places.
```{r}
search_space = ps(
  k = p_dbl(lower = 3, upper = 7.99, trafo = as.integer)
)
```

We construct the other objects needed for tuning.
```{r}
instance = TuningInstanceSingleCrit$new(
  task = task,
  learner = learner,
  resampling = rsmp("holdout"),
  measure = msr("classif.ce"),
  terminator = trm("evals", n_evals = 20),
  search_space = search_space)
```

We start the tuning and compare the results of the search space to the results in the space of the learners hyperparameter set.
```{r}
tuner$optimize(instance)
```

The optimal `k` is still a real number in the search space.
```{r}
instance$result_x_search_space
```

However, in the learners hyperparameters space, `k` is an integer value. 
```{r}
instance$result_x_domain
```

The archive shows us that for all real-valued `k` proposed by `r cran_pkg("GenSA")`, an integer-valued `k` in the learner hyperparameter space (`x_domain_k`) was created.
```{r}
as.data.table(instance$archive)[, c("k", "classif.ce", "x_domain_k")]
```

Internally, `r ref("TunerGenSA")` was given the parameter types of the search space and therefore suggested real numbers for `k`.
Before the performance of the different `k` values was evaluated, the transformation function of the `search_space` parameter set was called and `k` was transformed to an integer value.

Note that the tuner is not aware of the transformation.
This has two problematic consequences:
First, the tuner might propose different real valued configurations that after rounding end up to be already evaluated configurations and we end up with re-evaluating the same hyperparameter configuration.
This is only problematic, if we only optimze integer parameters.
Second, the rounding introduces discontinuities which can be problematic for some tuners. 

We successfully tuned a integer-valued hyperparameter with `r ref("TunerGenSA")` which is only suitable for an real-valued search space.
This technique is not limited to tuning problems.
`r ref("Optimizer")` in `r mlr_pkg("bbotk")` can be also used in the same way to produce points with integer parameters.
